label = "In all the above plots, the black points are the original training data,\nand coloured circles are predictions.")
#==============draw an example tree===================
# this is to illustrate the fundamental limitation of tree-based methods
# for out-of-sample extrapolation
tree <- rpart(y ~ x)
par(font.main = 1, col.main = "steelblue")
rpart.plot(tree, digits = 1,
box.palette = viridis(10, option = "D", begin = 0.85, end = 0),
shadow.col = "grey65", col = "grey99",
main = "Tree-based methods will give upper and lower bounds\nfor predicted values; in this example, the highest possible\npredicted value of y is 31, whenever x>84.")
((1-0.9)^2)/(2*0.9)
((1-0.01)^2)/(2*0.01)
library(tidyverse)
library(sf)
library(stars)
library(mapview)
library(lubridate)
library(dplyr)
library(rpart)
library(rpart.plot)
library(leaflet)    # for interactive maps
library(leafem)
library(mapedit)    # for drawing polygons interactively
library(scales)
library(ggplot2)
library(rstudioapi)
library(tidyr)
library(zoo)
library(np)         # kernel regression
library(kernlab)    # Gaussian processes
library(viridis)
library(terra)
library(signal)
library(abind)
model_folder <- "G:/Gedeelde drives/Team_BioDiv/5_Projecten/2024_Biodiversa_habitatpilot/WP2_3/Inundation/Validatie inundatie modellen/Validatie classificatie modellen/Rscripts - validatie classificatie modellen"
# Load the decision tree model
load(paste0(model_folder,"/jussila_decisiontree.RData"))
# Visualize the decision tree structure
rpart.plot(tree_jussila, tweak = 1, extra = 0)
View(tree_jussila)
tree_jussila[["frame"]]
View(tree_jussila)
tree_jussila[["call"]][["data"]]
print(tree_jussila)
summary(tree_jussila)
tree_jussila[["frame"]][["yval2"]]
View(tree_jussila)
model_folder <- "G:/Gedeelde drives/Team_BioDiv/5_Projecten/2024_Biodiversa_habitatpilot/WP2_3/Inundation/Validatie inundatie modellen/Validatie classificatie modellen/Rscripts - validatie classificatie modellen"
# Load the decision tree model
load(paste0(model_folder,"/jussila_decisiontree.RData"))
# Visualize the decision tree structure
rpart.plot(tree_jussila, tweak = 1, extra = 0)
View(tree_jussila)
tree_jussila[["frame"]]
library(tidyverse)
library(sf)
library(stars)
library(mapview)
library(lubridate)
library(dplyr)
library(rpart)
library(rpart.plot)
library(leaflet)    # for interactive maps
library(leafem)
library(mapedit)    # for drawing polygons interactively
library(scales)
library(ggplot2)
library(rstudioapi)
library(tidyr)
library(zoo)
library(np)         # kernel regression
library(kernlab)    # Gaussian processes
library(viridis)
library(terra)
library(signal)
library(abind)
model_folder <- "G:/Gedeelde drives/Team_BioDiv/5_Projecten/2024_Biodiversa_habitatpilot/WP2_3/Inundation/Validatie inundatie modellen/Validatie classificatie modellen/Rscripts - validatie classificatie modellen"
# Load the decision tree model
load(paste0(model_folder,"/jussila_decisiontree.RData"))
# Visualize the decision tree structure
rpart.plot(tree_jussila, tweak = 1, extra = 0)
ts_folder <- "G:/Gedeelde drives/Team_BioDiv/5_Projecten/2024_Biodiversa_habitatpilot/WP2_3/Inundation/Validatie inundatie modellen/Tijdsreeksanalyse studiegebieden/S2-tijdreeksdata"
obj <- read_stars(paste0(ts_folder,"/polygon_Demervallei_1.nc"))
# Sentinel-2 SCL class codes and definitions
dplyr::tibble(
SCL = 0:11,
SCL_name = c(
"No data",
"Saturated or defective",
"Dark area pixels",
"Cloud shadow",
"Vegetation",
"Bare soils",
"Water",
"Cloud low probability / Unclassified",
"Cloud medium probability",
"Cloud high probability",
"Thin cirrus",
"Snow or ice"
)
) -> scl_code
print(scl_code)
# Find all scenes with at least 95% of pixels classified as SCL 4, 5, or 6 (vegetation, bare soils, water)
# Mask out all remaining pixels with SCL values not equal to 4, 5, or 6
clear_dates <-
obj |>
as_tibble() |>
group_by(t) |>
summarize(prop_scl = sum(if_else(SCL %in% c(4,5,6), 1, 0)) / n()) |>
dplyr::filter(prop_scl > 0.80) |> # We can change this threshold if necessary.
pull(t)
obj_clear <-
obj |>
dplyr::filter(t %in% clear_dates) |>
mutate(across(everything(), ~ if_else(SCL %in% c(4, 5, 6), ., NA)))
rm(obj) # we won't use this object anymore.
obj_wetness <-
obj_clear |>
mutate(mndwi12 = (b03 - b12) / (b03 + b12),
mndwi11 = (b03 - b11) / (b03 + b11),
ndvi = (b8a - b04)/(b8a + b04),
ndwi_mf = (b03 - b8a)/(b03 + b8a),
ndmi_gao11 = (b8a - b11)/(b8a + b11))
View(obj_clear)
obj_wetness <-
obj_clear |>
mutate(b02 = B02,
b03 = B03,
b04 = B04,
b05 = B05,
b8A = B8A,
b11 = B11,
b12 = B12,
mndwi12 = (B03 - B12) / (B03 + B12),
mndwi11 = (B03 - B11) / (B03 + B11),
ndvi = (B8a - B04)/(B8a + B04),
ndwi_mf = (B03 - B8a)/(B03 + B8a),
ndmi_gao11 = (B8a - B11)/(B8a + B11))
obj_wetness <-
obj_clear |>
mutate(b02 = B02,
b03 = B03,
b04 = B04,
b05 = B05,
b8a = B8A,
b11 = B11,
b12 = B12,
mndwi12 = (B03 - B12) / (B03 + B12),
mndwi11 = (B03 - B11) / (B03 + B11),
ndvi = (B8a - B04)/(B8A + B04),
ndwi_mf = (B03 - B8A)/(B03 + B8A),
ndmi_gao11 = (B8A - B11)/(B8A + B11))
obj_wetness <-
obj_clear |>
mutate(b02 = B02,
b03 = B03,
b04 = B04,
b05 = B05,
b8a = B8A,
b11 = B11,
b12 = B12,
mndwi12 = (B03 - B12) / (B03 + B12),
mndwi11 = (B03 - B11) / (B03 + B11),
ndvi = (B8A - B04)/(B8A + B04),
ndwi_mf = (B03 - B8A)/(B03 + B8A),
ndmi_gao11 = (B8A - B11)/(B8A + B11))
rm(obj_clear)
obj_wetness %>% select(c("b02","b03"))
tree_jussila$terms
obj_wetness <- obj_wetness %>% select(c("b02","b03","b04","b05","b8a","b11","b12","mndwi11","mndwi12","ndvi","ndwi_mf","ndmi_gao11"))
r1_stars <- slice(obj_wetness, "t", 1)
r <- rast(r1_stars)
r_data_frame <- as.tibble(r)
View(r_data_frame)
tree_jussila$call
install.packages("mvoutlier")
library(mvoutlier)
combined <- train
labels <- c(rep("train", nrow(train)))
combined <- new
labels <- c(rep("new", nrow(new)))
new <- as.tibble(r)
combined <- new
labels <- c(rep("new", nrow(new)))
aq.plot(combined, label = labels)
aq.plot(combined)
update.packages(ask = FALSE, checkBuilt = TRUE)
if (!"tinytex" %in% rownames(installed.packages())) {
install.packages("tinytex")
}
# install the TinyTeX LaTeX distribution
if (!tinytex:::is_tinytex()) {
tinytex::install_tinytex()
}
# installation from inbo.r-universe
install.packages("INBOmd", repos = "https://inbo.r-universe.dev")
## alternative: installation from github
#if (!"remotes" %in% rownames(installed.packages())) {
#  install.packages("remotes")
#}
#remotes::install_github("inbo/INBOmd", dependencies = TRUE)
# add the local latex package contained in INBOmd to the TinyTeX install
tinytex::tlmgr_conf(
c("auxtrees", "add", system.file("local_tex", package = "INBOmd"))
)
# install some other needed latex packages
tinytex::tlmgr_install(c(
"inconsolata", "times", "tex", "helvetic", "dvips", "hyphen-dutch",
"hyphen-french"
))
# installation from inbo.r-universe
install.packages("INBOmd", repos = "https://inbo.r-universe.dev")
## alternative: installation from github
#if (!"remotes" %in% rownames(installed.packages())) {
#  install.packages("remotes")
#}
#remotes::install_github("inbo/INBOmd", dependencies = TRUE)
# add the local latex package contained in INBOmd to the TinyTeX install
tinytex::tlmgr_conf(
c("auxtrees", "add", system.file("local_tex", package = "INBOmd"))
)
# install some other needed latex packages
tinytex::tlmgr_install(c(
"inconsolata", "times", "tex", "helvetic", "dvips", "hyphen-dutch",
"hyphen-french"
))
getwd()
setwd("G:/Gedeelde drives/Team_BioDiv/5_Projecten/2024_Biodiversa_habitatpilot/WP2_3/INBO_Github_Biodiversa_Habitat_Pilot/Habitat_condition_indicators")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
# Chunk 2: author-info
cat("
<p>
<strong>Sebastiaan Verbesselt</strong><br>
Instituut voor Natuur- en Bosonderzoek<br>
<a href='https://orcid.org/0000-0003-0173-1123' target='_blank'>
<img src='G:/Gedeelde drives/Team_BioDiv/5_Projecten/2024_Biodiversa_habitatpilot/WP2_3/INBO_Github_Biodiversa_Habitat_Pilot/Habitat_condition_indicators/source/hydrology/media/Orcid_icon.png' alt='ORCID'
style='width:18px; vertical-align:middle; margin-right:4px;'>
https://orcid.org/0000-0003-0173-1123
</a>
</p>
<p>
<strong>Tytti Jussila</strong><br>
Finnish Environment Institute<br>
<a href='https://orcid.org/0000-0003-4646-0152' target='_blank'>
<img src='G:/Gedeelde drives/Team_BioDiv/5_Projecten/2024_Biodiversa_habitatpilot/WP2_3/INBO_Github_Biodiversa_Habitat_Pilot/Habitat_condition_indicators/source/hydrology/media/Orcid_icon.png' alt='ORCID'
style='width:18px; vertical-align:middle; margin-right:4px;'>
https://orcid.org/0000-0003-4646-0152
</a>
</p>
")
# Chunk 3
# Check automatically if you still need to install packages
list.of.packages <- c("tidyverse", "sf", "stars", "mapview", "lubridate", "dplyr", "rpart", "rpart.plot", "leaflet", "mapedit", "scales", "ggplot2", "rstudioapi","tidyr","zoo","np","kernlab","leafem","viridis","cubelyr","terra","signal","abind","dygraphs","xts","INBOmd","INBOtheme")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Load the packages
library(tidyverse)
library(sf)
library(stars)
library(mapview)
library(lubridate)
library(dplyr)
library(rpart)
library(rpart.plot)
library(leaflet)    # for interactive maps
library(leafem)
library(mapedit)    # for drawing polygons interactively
library(scales)
library(ggplot2)
library(rstudioapi)
library(tidyr)
library(zoo)
library(np)         # kernel regression
library(kernlab)    # Gaussian processes
library(viridis)
library(terra)
library(signal)
library(abind)
library(dygraphs)
library(xts)
library(INBOmd)
library(INBOtheme)
# Chunk 4
if (requireNamespace("rstudioapi", quietly = TRUE)) {
folder <- rstudioapi::selectDirectory(caption = "Select a folder")
print(folder)
} else {
message("rstudioapi not available; please install it with install.packages('rstudioapi').")
}
if (is.null(folder)){
folder <- "./source/hydrology/data"
}
# Chunk 5
wetlands <- st_read(paste0(folder,"/raw/wetlands_schulensmeer.gpkg")) |> st_transform(32631) # Transform to local crs system (WGS 84 / UTM zone 31N - EPSG:32631)
grasslands <- st_read(paste0(folder,"/raw/grasslands_schulensmeer.gpkg")) |> st_transform(32631) # Transform to local crs system (WGS 84 / UTM zone 31N - EPSG:32631)
polygons <- rbind(wetlands,grasslands)
plot(polygons["HAB1"])
# Chunk 6
AOI <- polygons %>% dplyr::filter(HAB1 == "6510_hu")
plot(AOI["HAB1"])
# Chunk 7
# First: proxy loading (fast)
obj <- read_stars(paste0(folder,"/intermediate/polygon_Demervallei_2.nc"), proxy = TRUE) # Region code: 1: Kloosterbeemden, 2: Schulensmeer, 3: Webbekomsbroek
obj2 <- read_stars(paste0(folder,"/intermediate/polygon_Demervallei_new_2.nc"), proxy = TRUE)
obj3 <- read_stars(paste0(folder,"/intermediate/polygon_Demervallei_last_2.nc"), proxy = TRUE)
# Ensure both have the same dimension names
# names(st_dimensions(obj))
# names(st_dimensions(obj2))
# names(st_dimensions(obj3))
# Drop any extra dimension (e.g., a band dimension named "X" or similar)
obj  <- adrop(obj)
obj2 <- adrop(obj2)
obj3 <- adrop(obj3)
# Now combine along time
combined <- c(obj, obj2, along = "t")
combined <- c(combined, obj3, along = "t")
# st_dimensions(obj)
# st_dimensions(obj2)
# st_dimensions(obj3)
st_dimensions(combined)
# Chunk 8
obj <- combined # Assign the combined datacube to the obj datacube (make a copy)
rm(obj2, obj3, combined) # Remove obj2, combined.
# Load now the data in memory:
obj <- st_as_stars(obj, along = "t")
# Chunk 9
wms_ortho_most_recent <- "https://geo.api.vlaanderen.be/OMWRGBMRVL/wms" # Most recent ortho image, winter, medium scale resolution.
wms_ortho <- "https://geo.api.vlaanderen.be/OMW/wms" # historical ortho images, winter, medium scale resolution.
wms_DEM <- "https://geo.api.vlaanderen.be/DHMV/wms" # Digital elevation model
wms_ANB <- "https://geo.api.vlaanderen.be/ANB/wms" # WMS layer ANB --> groenkaart (map of high vegetation)
# Chunk 10
# Load the decision tree model
load(paste0(folder,"/raw/jussila_decisiontree.RData"))
# Visualize the decision tree structure
rpart.plot(tree_jussila, tweak = 1, extra = 0)
# Chunk 11
outputfolder <- paste0(folder,"/processed")
# Chunk 12
# Ensure shapefile is in the right CRS (WGS84 lon/lat = EPSG:4326, since WCS expects that)
AOI_wgs84 <- st_transform(AOI, 4326)
# Extract bounding box
bb <- st_bbox(AOI_wgs84)
# Compute centroid of bbox
center_lng <- (bb["xmin"] + bb["xmax"]) / 2
center_lat <- (bb["ymin"] + bb["ymax"]) / 2
#
# map <- leaflet() %>%
#   addWMSTiles(
#     wms_ortho_most_recent,
#     layers = "Ortho",
#     options = WMSTileOptions(format = "image/png", transparent = FALSE), group = "Ortho") %>%
#   addWMSTiles(
#     wms_ANB,
#     layers = "Grnkrt21",
#     options = WMSTileOptions(format = "image/png", transparent = FALSE), group = "Grnkrt21") %>%
#   fitBounds(
#     lng1 = bb[["xmin"]],
#     lat1 = bb[["ymin"]],
#     lng2 = bb[["xmax"]],
#     lat2 = bb[["ymax"]]
#   )  %>%
#   addPolygons(data = AOI_wgs84, color = "red", weight = 2) %>%
#   addLayersControl(
#     baseGroups = c("Ortho","Grnkrt21"),
#     options = layersControlOptions(collapsed = FALSE)
#   )
#
#
# # Allow interactive drawing of polygons and save as trees_object
# drawn <- mapedit::editMap(map)
#
# # This returns an sf object with drawn features
# trees_object <- drawn[["drawn"]]
# trees_object <- st_make_valid(trees_object)
# st_write(trees_object, paste0(outputfolder, "/", "trees_SM.shp"))
# Chunk 13
# Inspect result
trees_object <- st_read(paste0(outputfolder, "/", "trees_SM.shp"))
print(trees_object)
par(mfrow=c(1,2))
plot(st_geometry(AOI_wgs84),border='grey',axes=T,main="Habitat boundary")
for (i in 1:nrow(trees_object)){
AOI_wgs84 <- st_difference(AOI_wgs84,trees_object[i,])
}
plot(st_geometry(AOI_wgs84,border='grey',axes=T,main="Habitat boundary without trees"))
par(mfrow=c(1,1))
# Chunk 14
# Website with the public wms files for Flanders: https://wms.michelstuyts.be/?lang=nl
layer2024 <- "OMWRGB24VL"# select the winter image of 2024
layer2023 <- "OMWRGB23VL" # select the winter image of 2023
layer2022 <- "OMWRGB22VL"# select the winter image of 2022
layer2021 <- "OMWRGB21VL"# select the winter image of 2021
layer2020 <- "OMWRGB20VL"# select the winter image of 2020
map <- leaflet() %>%
addWMSTiles(
wms_ortho,
layers = layer2020,
options = WMSTileOptions(format = "image/png", transparent = FALSE),
group = "OMWRGB20VL"
) %>%
addWMSTiles(
wms_ortho,
layers = layer2021,
options = WMSTileOptions(format = "image/png", transparent = FALSE),
group = "OMWRGB21VL"
) %>%
addWMSTiles(
wms_ortho,
layers = layer2022,
options = WMSTileOptions(format = "image/png", transparent = FALSE),
group = "OMWRGB22VL"
) %>%
addWMSTiles(
wms_ortho,
layers = layer2023,
options = WMSTileOptions(format = "image/png", transparent = FALSE),
group = "OMWRGB23VL"
) %>%
addWMSTiles(
wms_ortho,
layers = layer2024,
options = WMSTileOptions(format = "image/png", transparent = FALSE),
group = "OMWRGB24VL"
) %>%
fitBounds(
lng1 = bb[["xmin"]],
lat1 = bb[["ymin"]],
lng2 = bb[["xmax"]],
lat2 = bb[["ymax"]]
)  %>%
addPolygons(data = AOI_wgs84, color = "red", weight = 2) %>%
addLayersControl(
baseGroups = c("OMWRGB20VL","OMWRGB21VL","OMWRGB22VL","OMWRGB23VL","OMWRGB24V"),
options = layersControlOptions(collapsed = FALSE)
)
map
# Chunk 15
# Sentinel-2 SCL class codes and definitions
dplyr::tibble(
SCL = 0:11,
SCL_name = c(
"No data",
"Saturated or defective",
"Dark area pixels",
"Cloud shadow",
"Vegetation",
"Bare soils",
"Water",
"Cloud low probability / Unclassified",
"Cloud medium probability",
"Cloud high probability",
"Thin cirrus",
"Snow or ice"
)
) -> scl_code
print(scl_code)
# Find all scenes with at least 95% of pixels classified as SCL 4, 5, or 6 (vegetation, bare soils, water)
# Mask out all remaining pixels with SCL values not equal to 4, 5, or 6
clear_dates <-
obj |>
as_tibble() |>
group_by(t) |>
summarize(prop_scl = sum(if_else(SCL %in% c(4,5,6), 1, 0)) / n()) |>
dplyr::filter(prop_scl > 0.80) |> # We can change this threshold if necessary.
pull(t)
obj_clear <-
obj |>
dplyr::filter(t %in% clear_dates) |>
mutate(across(everything(), ~ if_else(SCL %in% c(4, 5, 6), ., NA)))
rm(obj) # we won't use this object anymore.
# Chunk 16
# Re-project your area without trees back to the local Belgian crs system:
AOI <- st_transform(AOI_wgs84, 32631)
# Mask out the polygon
obj_poly <-
obj_clear |>
st_crop(AOI)
rm(obj_clear) # we won't use this object anymore.
# Chunk 17
# Convert stars object to a data frame for prediction
obj_df <- as.data.frame(obj_poly)
names(obj_df) <- c("x","y","t","b02","b03","b04","b05","b08","b8a","b11","b12","SCL")
# Add/calculate the necessary indices for the classification
obj_df$mndwi12 <- (obj_df$b03 - obj_df$b12) / (obj_df$b03 + obj_df$b12)
obj_df$mndwi11 <- (obj_df$b03 - obj_df$b11) / (obj_df$b03 + obj_df$b11)
obj_df$ndvi <- (obj_df$b8a - obj_df$b04) / (obj_df$b8a + obj_df$b04)
obj_df$ndwi_mf <- (obj_df$b03 - obj_df$b8a) / (obj_df$b03 + obj_df$b8a)
obj_df$ndmi_gao11 <- (obj_df$b8a - obj_df$b11) / (obj_df$b8a + obj_df$b11)
# additional indices. STR should be a good indication of moisture
swir_to_str <- function(swir) { # function to calculate moisture index STR (based on SWIR band 11 or 12)
swir <- swir/10000
STR <- ((1-swir)^2)/(2*swir) #5.29
return(STR)
}
obj_df$STR1 <- swir_to_str(obj_df$b11)
obj_df$STR2 <- swir_to_str(obj_df$b12)
summary(obj_df)
# Chunk 18
# Check if there are no issues with the DN Values of the datacube (0-10000, so no offset with 1000).
# Check max values per column
(min_vals <- sapply(obj_df[,4:11], function(x) if(is.numeric(x)) min(x, na.rm = TRUE) else NA))
(max_vals <- sapply(obj_df[,4:11], function(x) if(is.numeric(x)) max(x, na.rm = TRUE) else NA))
# Warn if any numeric column has a minimum value that exceeds 1000
if (any(min_vals > 1000, na.rm = TRUE)) {
warning("Some columns in obj_df have min values greater than 1000")
}
# Warn if any numeric column exceeds 10000
if (any(max_vals > 10000, na.rm = TRUE)) {
warning("Some columns in obj_df have max values greater than 10000")
}
getwd()
