---
title: "Workshop Flanders - inundation time series"
author: 
  - name: "Sebastiaan Verbesselt"
    affiliation: "Instituut voor Natuur- en Bosonderzoek"
    orcid: "0000-0003-0173-1123"
  - name: "Tytti Jussila"
    affiliation: "Finnish Environment Institute"
    orcid: "0000-0003-4646-0152"
date: "`r Sys.Date()`"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    number_sections: true
    code_folding: show
knit: (function(input, ...) {rmarkdown::render(input, output_file="./source/hydrology/analysis/Workshop_Flanders-inundation_time_series.html")})
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r author-info, results='asis', echo=FALSE}
cat("
<p>
<strong>Sebastiaan Verbesselt</strong><br>
Instituut voor Natuur- en Bosonderzoek<br>
<a href='https://orcid.org/0000-0003-0173-1123' target='_blank'>
<img src='../media/Orcid_icon.png' alt='ORCID' 
     style='width:18px; vertical-align:middle; margin-right:4px;'> 
https://orcid.org/0000-0003-0173-1123
</a>
</p>

<p>
<strong>Tytti Jussila</strong><br>
Finnish Environment Institute<br>
<a href='https://orcid.org/0000-0003-4646-0152' target='_blank'>
<img src='../media/Orcid_icon.png' alt='ORCID' 
     style='width:18px; vertical-align:middle; margin-right:4px;'> 
https://orcid.org/0000-0003-4646-0152
</a>
</p>
")
```


# Workshop Flanders - inundation pilot:

**Instructions**

We are going to evaluate the study areas after our field visit (15/10/2025). Please follow along with the presentation and code. I will discuss each step in the PowerPoint presentation, after which you will have time to analyse the code blocks. I will ask questions from time to time, and you will have the opportunity to test things out and engage in discussion.

## Time series evaluation Webbekomsbroek

Before this workshop, we have already downloaded the datacube for the study area on OpenEO based on Hans's script. The datacube and the other required data can be found here: "./source/hydrology/data/Retrieve_Datacube_Open_EO-Demervalley.Rmd".

Please download the file together with the shapefile in the folder.

### Step 1: Upload the required libraries/packages

```{r load libraries, warning = FALSE, message = FALSE}
# Check automatically if you still need to install packages
list.of.packages <- c("tidyverse", "sf", "stars", "mapview", "lubridate", "dplyr", "rpart", "rpart.plot", "leaflet", "mapedit", "scales", "ggplot2", "rstudioapi","tidyr","zoo","np","kernlab","leafem","viridis","cubelyr","terra","signal","abind","INBOmd","INBOtheme")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Load the packages
library(tidyverse)
library(sf)
library(stars)
library(mapview)
library(lubridate)
library(dplyr)
library(rpart)
library(rpart.plot)
library(leaflet)    # for interactive maps
library(leafem)
library(mapedit)    # for drawing polygons interactively
library(scales)
library(ggplot2)
library(rstudioapi)
library(tidyr)
library(zoo)
library(np)         # kernel regression
library(kernlab)    # Gaussian processes
library(viridis)
library(terra)
library(signal)
library(abind)
library(INBOmd)
library(INBOtheme)
```

### Step 2: Load the datasets

Refer to the location of your data folder (interactively):

```{r select the datafolder interactively}
if (requireNamespace("rstudioapi", quietly = TRUE)) {
  folder <- rstudioapi::selectDirectory(caption = "Select a folder")
  print(folder)
} else {
  message("rstudioapi not available; please install it with install.packages('rstudioapi').")
}

if (is.null(folder)){
  folder <- "./source/hydrology/data/"
} 

```

Load the data sets:

1.  The area of interest (AOI):

```{r load the polygons}
polygons <- st_read(paste0(folder,"raw/Webbekom_5testsites_demo.gpkg")) |> st_transform(32631) # Transform to local crs system (WGS 84 / UTM zone 31N - EPSG:32631)
polygons$ID <- c(1:5)
plot(polygons["ID"])
```

Select your area:

```{r select the AOI}
AOI <- polygons %>% dplyr::filter(ID == 2)
plot(AOI["ID"])
```

2.  Load the datacube:

```{r load the NetCDF datacubes}
# First: proxy loading (fast)
obj <- read_stars(paste0(folder,"intermediate/polygon_Demervallei_3.nc"), proxy = TRUE) # Region code: 1: Kloosterbeemden, 2: Schulensmeer, 3: Webbekomsbroek
obj2 <- read_stars(paste0(folder,"intermediate/polygon_Demervallei_new_3.nc"), proxy = TRUE) 

obj3 <- read_stars(paste0(folder,"intermediate/polygon_Demervallei_last_3.nc"), proxy = TRUE) 
 
# Ensure both have the same dimension names
# names(st_dimensions(obj))
# names(st_dimensions(obj2))
# names(st_dimensions(obj3))

# Drop any extra dimension (e.g., a band dimension named "X" or similar)
obj  <- adrop(obj)
obj2 <- adrop(obj2)
obj3 <- adrop(obj3)
 
# Now combine along time
combined <- c(obj, obj2, along = "t")
combined <- c(combined, obj3, along = "t")
# st_dimensions(obj)
# st_dimensions(obj2)
# st_dimensions(obj3)
st_dimensions(combined)
```

Remove the data layers that we wont use in the workshop to make sure we have enough free memory.

```{r combine the datacubes into 1 datacube}
obj <- combined # Assign the combined datacube to the obj datacube (make a copy)
rm(obj2, obj3, combined) # Remove obj2, combined.  

# Load now the data in memory:
obj <- st_as_stars(obj, along = "t")
```

3.  Load the WMS links for the ortho images of Flanders:

```{r connect to the wms layers}
wms_ortho_most_recent <- "https://geo.api.vlaanderen.be/OMWRGBMRVL/wms" # Most recent ortho image, winter, medium scale resolution.
wms_ortho <- "https://geo.api.vlaanderen.be/OMW/wms" # historical ortho images, winter, medium scale resolution.
wms_DEM <- "https://geo.api.vlaanderen.be/DHMV/wms" # Digital elevation model
```

4.  Load Tytti's model:

```{r load Jussila model}
# Load the decision tree model
load(paste0(folder,"raw/jussila_decisiontree.RData")) 

# Visualize the decision tree structure
rpart.plot(tree_jussila, tweak = 1, extra = 0)
```

5.  The GPS points (select immediately the points that fall within the selected polygon):

```{r load the gps points}
# Load the points
points <- st_read(paste0(folder,"raw/survey_points_HabitatPilot.gpkg"))

# Change multipoint to single point (if necessary)
points_single <- st_cast(points, "POINT")
points_single

# Select points that overlap with 
points_single <- points_single |> st_transform(st_crs(AOI))
points_single <- points_single[st_intersects(points_single, AOI, sparse = FALSE), ]
points_single

```

### Step 3: Data pre-processing

We will exclude "trees" from the image based on the most recent ortho image of Flanders. This because the inundation models are developed for "open" habitats. Normally, we could use regional datasets or European datasets for forests / tree cover / high vegetation cover to do the masking. E.g.: <https://land.copernicus.eu/en/products/high-resolution-layer-forests-and-tree-cover> (last map made in 2021). But in this exercise, we will do it interactively.

```{r tree_masking, class.source = 'fold-hide'}
# Ensure shapefile is in the right CRS (WGS84 lon/lat = EPSG:4326, since WCS expects that)
AOI_wgs84 <- st_transform(AOI, 4326)
points_wgs84 <- st_transform(points_single, 4326)



# Extract bounding box
bb <- st_bbox(AOI_wgs84)

# Compute centroid of bbox
center_lng <- (bb["xmin"] + bb["xmax"]) / 2
center_lat <- (bb["ymin"] + bb["ymax"]) / 2

map <- leaflet() %>%
  addWMSTiles(
    wms_ortho_most_recent,
    layers = "Ortho",
    options = WMSTileOptions(format = "image/png", transparent = FALSE)
  ) %>%
  fitBounds(
    lng1 = bb[["xmin"]],
    lat1 = bb[["ymin"]],
    lng2 = bb[["xmax"]],
    lat2 = bb[["ymax"]]
  )  %>%
  addPolygons(data = AOI_wgs84, color = "red", weight = 2) %>%
  addMarkers(
    data = points_wgs84,
    lng = st_coordinates(points_wgs84)[,1],
    lat = st_coordinates(points_wgs84)[,2],
    popup = points_wgs84$label
  )


# Allow interactive drawing of polygons and save as trees_object
drawn <- mapedit::editMap(map)

# This returns an sf object with drawn features
trees_object <- drawn[["drawn"]]
trees_object <- st_make_valid(trees_object)
# Inspect result
print(trees_object)

par(mfrow=c(1,2))
plot(st_geometry(AOI_wgs84),border='grey',axes=T,main="Habitat boundary")
for (i in 1:nrow(trees_object)){
   AOI_wgs84 <- st_difference(AOI_wgs84,trees_object[i,])
}
plot(st_geometry(AOI_wgs84,border='grey',axes=T,main="Habitat boundary without trees"))
par(mfrow=c(1,1))
```

See how inundation changes in in the past (based on winter ortho images) for your area. Select the year the want to visualize.

```{r look at different ortho images for the study area, class.source = 'fold-hide'}
# Website with the public wms files for Flanders: https://wms.michelstuyts.be/?lang=nl 
layer2024 <- "OMWRGB24VL"# select the winter image of 2024
layer2023 <- "OMWRGB23VL" # select the winter image of 2023
layer2022 <- "OMWRGB22VL"# select the winter image of 2022
layer2021 <- "OMWRGB21VL"# select the winter image of 2021
layer2020 <- "OMWRGB20VL"# select the winter image of 2020

map <- leaflet() %>%
  addWMSTiles(
    wms_ortho,
    layers = layer2020,
    options = WMSTileOptions(format = "image/png", transparent = FALSE),
    group = "OMWRGB20VL"
  ) %>%
  addWMSTiles(
    wms_ortho,
    layers = layer2021,
    options = WMSTileOptions(format = "image/png", transparent = FALSE),
    group = "OMWRGB21VL"
  ) %>%
  addWMSTiles(
    wms_ortho,
    layers = layer2022,
    options = WMSTileOptions(format = "image/png", transparent = FALSE),
    group = "OMWRGB22VL"
  ) %>%
  addWMSTiles(
    wms_ortho,
    layers = layer2023,
    options = WMSTileOptions(format = "image/png", transparent = FALSE),
    group = "OMWRGB23VL"
  ) %>%
  addWMSTiles(
    wms_ortho,
    layers = layer2024,
    options = WMSTileOptions(format = "image/png", transparent = FALSE),
    group = "OMWRGB24VL"
  ) %>%
  fitBounds(
    lng1 = bb[["xmin"]],
    lat1 = bb[["ymin"]],
    lng2 = bb[["xmax"]],
    lat2 = bb[["ymax"]]
  )  %>%
  addPolygons(data = AOI_wgs84, color = "red", weight = 2) %>%
  addMarkers(
    data = points_wgs84,
    lng = st_coordinates(points_wgs84)[,1],
    lat = st_coordinates(points_wgs84)[,2],
    popup = points_wgs84$label
  ) %>%
  addLayersControl(
    baseGroups = c("OMWRGB20VL","OMWRGB21VL","OMWRGB22VL","OMWRGB23VL","OMWRGB24V"),
    options = layersControlOptions(collapsed = FALSE)
  )

map
```

Most recent:

Date winter images study area:

-   most recent: 5/03/2025

-   2024: 06/04/2024

-   2023: 01/03/2023

-   2022: 04/03/2022

-   2021: 01/03/2021

-   2020: 24/03/2020

```{r, eval = FALSE, echo = FALSE}
# layer <- "OMWRGB24VL_vdc"# select the winter image of 2020
# 
# map <- leaflet() %>%
#   addWMSTiles(
#     wms_ortho,
#     layers = layer,
#     options = WMSTileOptions(format = "image/png", transparent = FALSE)
#   ) %>%
#   fitBounds(
#     lng1 = bb[["xmin"]],
#     lat1 = bb[["ymin"]],
#     lng2 = bb[["xmax"]],
#     lat2 = bb[["ymax"]]
#   )  %>%
#   addPolygons(data = AOI_wgs84, color = "red", weight = 2)
# 
# map
```

Preprocess the datacube:

-   Cloud and shadow masking

```{r, cloud masking}
# Sentinel-2 SCL class codes and definitions
dplyr::tibble(
  SCL = 0:11,
  SCL_name = c(
    "No data",
    "Saturated or defective",
    "Dark area pixels",
    "Cloud shadow",
    "Vegetation",
    "Bare soils",
    "Water",
    "Cloud low probability / Unclassified",
    "Cloud medium probability",
    "Cloud high probability",
    "Thin cirrus",
    "Snow or ice"
  )
) -> scl_code
print(scl_code)

# Find all scenes with at least 95% of pixels classified as SCL 4, 5, or 6 (vegetation, bare soils, water)
# Mask out all remaining pixels with SCL values not equal to 4, 5, or 6
clear_dates <-
  obj |> 
  as_tibble() |> 
  group_by(t) |> 
  summarize(prop_scl = sum(if_else(SCL %in% c(4,5,6), 1, 0)) / n()) |> 
  dplyr::filter(prop_scl > 0.80) |> # We can change this threshold if necessary. 
  pull(t) 


obj_clear <-
  obj |>
  dplyr::filter(t %in% clear_dates) |>
  mutate(across(everything(), ~ if_else(SCL %in% c(4, 5, 6), ., NA)))

rm(obj) # we won't use this object anymore.
```

***Question 1: which cloud cover threshold should we use? We now use a 5% threshold.***

-   Regional masking: limit the datacube to your area (without trees)

```{r, regional masking}
# Re-project your area without trees back to the local Belgian crs system:
AOI <- st_transform(AOI_wgs84, 32631)

# Mask out the polygon
obj_poly <-
  obj_clear |>
  st_crop(AOI)

rm(obj_clear) # we won't use this object anymore.
```

-   Calculate the different vegetation indices

```{r, calculate different vegetation indices}
# Convert stars object to a data frame for prediction
obj_df <- as.data.frame(obj_poly)
names(obj_df) <- c("x","y","t","b02","b03","b04","b05","b08","b8a","b11","b12","SCL")
# Add/calculate the necessary indices for the classification
obj_df$mndwi12 <- (obj_df$b03 - obj_df$b12) / (obj_df$b03 + obj_df$b12)
obj_df$mndwi11 <- (obj_df$b03 - obj_df$b11) / (obj_df$b03 + obj_df$b11)
obj_df$ndvi <- (obj_df$b8a - obj_df$b04) / (obj_df$b8a + obj_df$b04)
obj_df$ndwi_mf <- (obj_df$b03 - obj_df$b8a) / (obj_df$b03 + obj_df$b8a) 
obj_df$ndmi_gao11 <- (obj_df$b8a - obj_df$b11) / (obj_df$b8a + obj_df$b11) 

# additional indices. STR should be a good indication of moisture
swir_to_str <- function(swir) { # function to calculate moisture index STR (based on SWIR band 11 or 12)
  swir <- swir/10000
  STR <- ((1-swir)^2)/(2*swir) #5.29
  return(STR)
}
obj_df$STR1 <- swir_to_str(obj_df$b11)
obj_df$STR2 <- swir_to_str(obj_df$b12)
summary(obj_df)
```

Since the radiometric values of Sentinel-2 L2 products can have a different offset values (due to the change in processing baseline (4.00), introduces in January 2022): 0 or 1000. the DN (Digital Number) values have a **radiometric offset of -1000 applied to ensure negative values can be represented**. We check the min. and max. values within our datacube. [https://sentiwiki.copernicus.eu/web/s2-processing#S2Processing-RadiometricOffset](#0)

```{r, check DN values}
# Check if there are no issues with the DN Values of the datacube (0-10000, so no offset with 1000).
# Check max values per column
(min_vals <- sapply(obj_df[,4:11], function(x) if(is.numeric(x)) min(x, na.rm = TRUE) else NA))
(max_vals <- sapply(obj_df[,4:11], function(x) if(is.numeric(x)) max(x, na.rm = TRUE) else NA))
# Warn if any numeric column has a minimum value that exceeds 1000
if (any(min_vals > 1000, na.rm = TRUE)) {
  warning("Some columns in obj_df have min values greater than 1000") 
}

# Warn if any numeric column exceeds 10000
if (any(max_vals > 10000, na.rm = TRUE)) {
  warning("Some columns in obj_df have max values greater than 10000") 
}
```

```{r, save the original datacube dimensions}
# Keep the original x, y, t dimension form your stars object.
# If we convert our stars object to a dataframe for classification, we lose the x, y, t information. When we want to convert it back to an array/datacube, we need to know the original dimensions.

(dim <- st_dimensions(obj_poly)) # See the dimensions of x y and t
nx <- dim$x$to - dim$x$from  + 1  # size in the x dimension
ny <- dim$y$to - dim$y$from  + 1  # size in the y dimension
nt <- dim$t$to - dim$t$from  + 1  # size in the t dimension
```


### Step 4: Classification {.tabset}

#### Jussila's (Jussila et al., 2024) inundation classification

```{r Jussila classfication, class.source = 'fold-hide'}
predictions <- predict(tree_jussila, obj_df, type = "class")

# Convert factor to numeric codes
pred_numeric <- as.numeric(predictions)

# Set predictions to NA if the corresponding row in obj_df contains any NA (masked out values are set to NA instead of 1 or 2)
pred_numeric[!complete.cases(obj_df)] <- NA

# Store levels for later labeling
(pred_levels <- levels(predictions))

# Reshape to array
pred_array <- array(pred_numeric, dim = c(nx, ny, nt))

# Create stars object
obj_classified <- st_as_stars(pred_array, dimensions = st_dimensions(obj_poly))
st_crs(obj_classified) <- st_crs(obj_poly)

# Visualize
# Convert the stars object to factor using st_set_dimensions
obj_classified_factor <- obj_classified[AOI]
obj_classified_factor[[1]] <- factor(
  obj_classified_factor[[1]],
  levels = c(1, 2),
  labels = pred_levels
)

# Plot with discrete scale
ggplot() +
  ggtitle("Class. (Jussila)") + 
  geom_stars(data = obj_classified_factor) +
  geom_sf(data = AOI, fill = NA, color = "red", linewidth = 1) +
  facet_wrap(~t, ncol = 25) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 6),   # <-- make facet titles smaller,
    axis.text = element_blank(),          # remove axis tick labels
    axis.ticks = element_blank(),         # remove tick marks
  ) +
  scale_fill_manual(
    name = "Class",
    values = c("dry" = "tan", "water" = "blue")
  )
```

#### Wiw (Lefebre et al., 2019) inundation classification

```{r wiw classification, class.source = 'fold-hide'}
watercl_wiw <- obj_df$b8a <= 1804 & obj_df$b12 <= 1131
watercl_wiw <- watercl_wiw*1 
pred_levels <- c("dry" , "water")

# Reshape to array
wiw_array <- array(watercl_wiw, dim = c(nx, ny, nt))

# Create stars object
obj_classified_wiw <- st_as_stars(wiw_array, dimensions = st_dimensions(obj_poly))
st_crs(obj_classified_wiw) <- st_crs(obj_poly)

# Visualize
# Convert the stars object to factor using st_set_dimensions
obj_classified_wiw_factor <- obj_classified_wiw[AOI]
obj_classified_wiw_factor[[1]] <- factor(
  obj_classified_wiw_factor[[1]],
  levels = c(0, 1),
  labels = pred_levels
)

# Plot with discrete scale
ggplot() +
  ggtitle("Class. (WiW)") + 
  geom_stars(data = obj_classified_wiw_factor) +
  geom_sf(data = AOI, fill = NA, color = "red", linewidth = 1) +
  facet_wrap(~t, ncol = 25) +
  theme_minimal()+
    theme(
    strip.text = element_text(size = 6),   # <-- make facet titles smaller,
    axis.text = element_blank(),          # remove axis tick labels
    axis.ticks = element_blank(),         # remove tick marks
  ) +
  scale_fill_manual(
    name = "Class",
    values = c("dry" = "tan", "water" = "blue")
  )
```

### Visual comparison between the models

***Question 2: can you already spot some differences between the two models?***

We can check the output of both classifications and compare it with an ortho image with the same date. E.g. 01/03/2023.

```{r check output for 1 of March 2023, class.source = 'fold-hide'}
# Extract the time values
times <- st_get_dimension_values(obj_classified_wiw, "t")

# Define your desired time
target_time <- as.POSIXct("2023-03-01", tz = "UTC")

# Find index of the nearest timestamp
i <- which.min(abs(times - target_time))

# Extract that layer
layer_2023_03_01_wiw <- obj_classified_wiw[,,,i]
layer_2023_03_01_Tytti <- obj_classified[,,,i] - 1 # convert values [1,2] --> [0,1]


layer_2023_03_01_wiw <- layer_2023_03_01_wiw %>% st_warp(crs=4326)
layer_2023_03_01_Tytti <- layer_2023_03_01_Tytti %>% st_warp(crs=4326)

# Define your color palette
palette_function <- function(stars_data){
  if (min(stars_data, na.rm=T) == max(stars_data, na.rm=T)){
    if (max(stars_data, na.rm=T)==1){
      palette <- colorFactor(palette = "blue",domain = 1,na.color = "transparent")
    } else {
      palette <- colorFactor(palette = "tan",domain = 0,na.color = "transparent")
    }
      
  }else {
    palette <- colorFactor(palette = c("tan","blue"),domain= c(0,1),na.color = "transparent")
  }
}

# Base map (your existing code)
layer <- "OMWRGB23VL"

map <- leaflet() %>%
  addTiles(group = "OpenStreetMap") %>%  # <-- Adds OSM as base map
  addWMSTiles(
    wms_ortho,
    layers = layer,
    options = WMSTileOptions(format = "image/png", transparent = FALSE),
    group = "OMWRGB20VL"
  ) %>%
  addWMSTiles(
    wms_DEM,
    layers = "DHMV_II_HILL_25cm",
    options = WMSTileOptions(format = "image/png", transparent = TRUE),
    group = "DHMV_II_HILL_25cm"
  ) %>%
  fitBounds(
    lng1 = bb[["xmin"]],
    lat1 = bb[["ymin"]],
    lng2 = bb[["xmax"]],
    lat2 = bb[["ymax"]]
  ) %>%
  addPolygons(data = AOI_wgs84, color = "red", weight = 2) %>%
  addMarkers(
    data = points_wgs84,
    lng = st_coordinates(points_wgs84)[,1],
    lat = st_coordinates(points_wgs84)[,2],
    popup = points_wgs84$label
  ) %>%
  addStarsImage(
    layer_2023_03_01_wiw,
    colors = palette_function(layer_2023_03_01_wiw[["X"]]),
    opacity = 0.8,
    group = "2023-03-01 Wiw"
  ) %>%
  addStarsImage(
    layer_2023_03_01_Tytti,
    colors = palette_function(layer_2023_03_01_Tytti[["X"]]),
    opacity = 0.8,
    group = "2023-03-01 Tytti"
  ) %>%
  addLayersControl(
    baseGroups = c("OpenStreetMap","OMWRGB23VL", "DHMV_II_HILL_25cm"),
    overlayGroups = c("2023-03-01 Wiw", "2023-03-01 Tytti"),
    options = layersControlOptions(collapsed = FALSE)
  )

map
```

### Step 5: Visualize output for the last available date

Compare the classification results based on the last available Sentinel-2 image and compare it with the field data of 15/10/2025 (GPS coordinates).

```{r check model output for last available date with the datacube, class.source = 'fold-hide'}
# Extract the time values
times <- st_get_dimension_values(obj_classified_wiw, "t")

# Define your desired time
target_time <- as.POSIXct("2025-10-15", tz = "UTC")

# Find index of the nearest timestamp
i <- which.min(abs(times - target_time))

# Extract that layer
layer_last_wiw <- obj_classified_wiw[,,,i]
layer_last_Tytti <- obj_classified[,,,i] - 1 # convert values [1,2] --> [0,1]

layer_last_wiw <- layer_last_wiw %>% st_warp(crs=4326)
layer_last_Tytti <- layer_last_Tytti %>% st_warp(crs=4326)

# Extract the time value from the layer
date_value <- st_get_dimension_values(obj_classified_wiw[,,,i], "t")
date_value

# Define your color palette
palette_function <- function(stars_data){
  if (min(stars_data, na.rm=T) == max(stars_data, na.rm=T)){
    if (max(stars_data, na.rm=T)==1){ # Check if your layer has 0 and 1 values, only 0 values (completely dry) or only 1 values (completely inundated). If you only define 1 color palette, the results will be interpolated.  
      palette <- colorFactor(palette = "blue",domain = 1,na.color = "transparent")
    } else {
      palette <- colorFactor(palette = "tan",domain = 0,na.color = "transparent")
    }
      
  }else {
    palette <- colorFactor(palette = c("tan","blue"),domain= c(0,1),na.color = "transparent")
  }
}


# Create map with OSM background
map <- leaflet() %>%
  addTiles(group = "OpenStreetMap") %>%  # <-- Adds OSM as base map
  addWMSTiles(
    wms_ortho,
    layers = layer,
    options = WMSTileOptions(format = "image/png", transparent = FALSE),
    group = "OMWRGB20VL"
  ) %>%
  addWMSTiles(
    wms_DEM,
    layers = "DHMV_II_HILL_25cm",
    options = WMSTileOptions(format = "image/png", transparent = TRUE),
    group = "DHMV_II_HILL_25cm"
  ) %>%
  fitBounds(
    lng1 = bb[["xmin"]],
    lat1 = bb[["ymin"]],
    lng2 = bb[["xmax"]],
    lat2 = bb[["ymax"]]
  ) %>%
  addPolygons(data = AOI_wgs84, color = "red", weight = 2) %>%
  addMarkers(
    data = points_wgs84,
    lng = st_coordinates(points_wgs84)[,1],
    lat = st_coordinates(points_wgs84)[,2],
    popup = points_wgs84$label
  ) %>%
  addStarsImage(
    layer_last_wiw,
    colors = palette_function(layer_last_wiw[["X"]]),
    opacity = 0.8,
    group = paste0(date_value, " Wiw. cl")
  ) %>%
  addStarsImage(
    layer_last_Tytti,
    colors = palette_function(layer_last_Tytti[["X"]]),
    opacity = 0.8,
    group = paste0(date_value, " Juss. cl")
  ) %>%
  addLayersControl(
    baseGroups = c("OpenStreetMap","OMWRGB20VL", "DHMV_II_HILL_25cm"),
    overlayGroups = c(paste0(date_value, " Wiw. cl"), paste0(date_value, " Juss. cl")),
    options = layersControlOptions(collapsed = FALSE)
  )

map
```

You can also visualize a vegetation/soil moisture index for the last date.

Add soil moisture/wetness indices to your stars object.

```{r create a wetness stars object}
obj_wetness <-
  obj_poly |>
  mutate(NDMI = (B8A - B11) / (B8A + B11), # Gao's Moisture index
         NDWI = (B03 - B8A) / (B03 + B8A), # Mcfeeters Water index
         NDPI = (B03-B11)/(B03+B11), # Pond index. from slovakia Clizsky potok example 
         STR = ((1-B11/10000)^2)/(2*B11/10000)) # Transformed SWIR. Should be linearly correlated with soil moisture (Sadeghi et al.,2017, https://doi.org/10.1016/j.rse.2017.05.041)
```

Visualize the different soil moisture indices for the last available date.

```{r check indices output for last available date with the datacube, class.source = 'fold-hide'}
# Extract that layer
obj_wetness_last <- obj_wetness[,,,i]

obj_wetness_last <- obj_wetness_last %>% st_warp(crs=4326)

# Extract the time value from the layer
date_value <- st_get_dimension_values(obj_wetness_last, "t")
date_value

# Define a viridis palette (yellow -> blue)
# direction = -1 flips the default viridis (blue -> yellow) to yellow -> blue
viridis_pal <- viridis::viridis(256, option = "D", direction = -1)

# You can define a function to generate color scales for each layer dynamically
palette_function <- function(layer) {
  # Extract the numeric values safely
  layer_values <- as.vector(st_as_stars(layer)[[1]])
  
  leaflet::colorNumeric(
    palette = viridis_pal,
    domain = layer_values,
    na.color = "transparent"
  )
}

# Create map with OSM background
map <- leaflet() %>%
  addTiles(group = "OpenStreetMap") %>%
  addWMSTiles(
    wms_ortho,
    layers = layer,
    options = WMSTileOptions(format = "image/png", transparent = FALSE),
    group = "OMWRGB20VL"
  ) %>%
  addWMSTiles(
    wms_DEM,
    layers = "DHMV_II_HILL_25cm",
    options = WMSTileOptions(format = "image/png", transparent = TRUE),
    group = "DHMV_II_HILL_25cm"
  ) %>%
  fitBounds(
    lng1 = bb[["xmin"]],
    lat1 = bb[["ymin"]],
    lng2 = bb[["xmax"]],
    lat2 = bb[["ymax"]]
  ) %>%
  addPolygons(data = AOI_wgs84, color = "red", weight = 2) %>%
  addMarkers(
    data = points_wgs84,
    lng = st_coordinates(points_wgs84)[,1],
    lat = st_coordinates(points_wgs84)[,2],
    popup = points_wgs84$label
  ) %>%
  addStarsImage(
    -obj_wetness_last["B11"],
    colors = palette_function(-obj_wetness_last["B11"]), # multiply with -1 (because high values normally inidicate dry spots, not wet spots like in the other indices).
    opacity = 0.8,
    group = paste0(date_value, " B11")
  ) %>%
  addStarsImage(
    obj_wetness_last["NDWI"],
    colors = palette_function(obj_wetness_last["NDWI"]),
    opacity = 0.8,
    group = paste0(date_value, " NDWI")
  ) %>%
  addStarsImage(
    obj_wetness_last["NDMI"],
    colors = palette_function(obj_wetness_last["NDMI"]),
    opacity = 0.8,
    group = paste0(date_value, " NDMI")
  ) %>%
  addStarsImage(
    obj_wetness_last["NDPI"],
    colors = palette_function(obj_wetness_last["NDPI"]),
    opacity = 0.8,
    group = paste0(date_value, " NDPI")
  ) %>%
  addStarsImage(
    obj_wetness_last["STR"],
    colors = palette_function(obj_wetness_last["STR"]),
    opacity = 0.8,
    group = paste0(date_value, " STR")
  ) %>%
  addLayersControl(
    baseGroups = c("OpenStreetMap","OMWRGB20VL", "DHMV_II_HILL_25cm"),
    overlayGroups = c(
      paste0(date_value, " B11"),
      paste0(date_value, " NDWI"),
      paste0(date_value, " NDMI"),
      paste0(date_value, " NDPI"),
      paste0(date_value, " STR")
    ),
    options = layersControlOptions(collapsed = FALSE)
  )

map
```

***Question 3: What can we conclude based form the last available Sentinel-2 image data? Does it match with our observations in the field?***

### Step 6: Indicator analysis

***Question 4: in which case do we want to monitor on pixel level / on plot level?***

Problem of missing data:

```{r}
plot(obj_classified[,,,130],main="2024-08-19",col=c("tan"))
```

We first analyse without dealing with missing values.

-   Proportion of inundation

```{r}
# Calculate the proportion of "water" pixels for each times tamp and visualize
# Convert the classified stars object to a tibble
classified_pixels <- as_tibble(obj_classified[AOI])

# Rename the column for clarity and filter out NA values
names(classified_pixels)[which(names(classified_pixels) == "X")] <- "Class"
classified_pixels <- classified_pixels %>% dplyr::filter(!is.na(Class))

# Calculate total pixels and water pixels for each time step
water_proportion_data <- classified_pixels %>%
  group_by(t) %>%
  summarize(
    total_pixels = n(),
    water_pixels = sum(Class == 2, na.rm = TRUE), # Class 2 is 'water'
    .groups = "drop"
  ) %>%
  mutate(
    proportion_water = water_pixels / total_pixels
  )

# Print the resulting tibble with proportions
print(water_proportion_data)

# Visualize the time series of water proportion
ggplot(water_proportion_data, aes(x = t, y = proportion_water)) +
  geom_line(color = "blue", size = 1.2) +
  geom_point(color = "blue", size = 2) +
  labs(
    title = "Proportion of Inundated Pixels Over Time",
    subtitle = "Within the selected habitat polygon boundary",
    x = "Date",
    y = "Proportion of Water Pixels"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

Be aware you have missing data! Visualize the true time series.

```{r}
# Fill in every 5-day step (revisit time Sentinel 2 --> for Belgium even up to 2/3 days revisit time).
water_proportion_data2 <- water_proportion_data %>%
  mutate(t = as.Date(t))

water_proportion_data_complete <- water_proportion_data2 %>%
  complete(t = seq.Date(min(t), max(t), by = "5 days"))

ggplot(water_proportion_data_complete, aes(x = t, y = proportion_water)) +
  geom_line(color = "blue", size = 1.2, na.rm = FALSE) +
  geom_point(color = "blue", size = 2) +
  labs(
    title = "Proportion of Inundated Pixels Over Time",
    subtitle = "Within the selected habitat polygon boundary",
    x = "Date",
    y = "Proportion of Water Pixels"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

Water/soil moisture indices

```{r}
Juss_cl <- obj_classified-1 # convert values form 1-2 to 0-1
obj_wetness <- c(obj_wetness,Juss_cl)
obj_wetness <- c(obj_wetness,obj_classified_factor)
obj_wetness <- c(obj_wetness,obj_classified_wiw)
obj_wetness <- c(obj_wetness,obj_classified_wiw_factor)
names(obj_wetness)[14] <- "Juss_cl"
names(obj_wetness)[15] <- "Juss_cl_fact"
names(obj_wetness)[16] <- "Wiw_cl"
names(obj_wetness)[17] <- "Wiw_cl_fact"


obj_wetness


# STR index
plot(
  obj_wetness[13],
  col = rev(hcl.colors(100, "viridis")),  # 2 shades of blue
  key.pos = 1,                    # put legend at the bottom (1 = below, 2 = left, 3 = above, 4 = right)
)
```

Create a summary table (without and with complete time steps) so time series of summary statistics of our AOI can be visualized.

```{r}
# summarise
table_all <- 
  obj_wetness[,,,] |>  
  as_tibble() |>
  group_by(t) |>
  summarize(
    valid_pixels = sum(!is.na(NDMI)),
    NDMI_mean = mean(NDMI, na.rm = TRUE),
    NDMI_sd   = sd(NDMI, na.rm = TRUE),
    NDWI_mean = mean(NDWI, na.rm = TRUE),
    NDWI_sd = sd(NDWI, na.rm = TRUE),
    NDPI_mean = mean(NDPI, na.rm = TRUE),
    NDPI_sd = sd(NDPI, na.rm = TRUE),
    STR_mean  = mean(STR, na.rm = TRUE),
    STR_sd = sd(STR, na.rm = TRUE),
    B11_mean  = mean(B11, na.rm = TRUE),
    B11_sd  = sd(B11, na.rm = TRUE)
  )

# Fill missing dates (5-day steps)
table_all_complete <- table_all %>%
  mutate(t = as.Date(t)) %>% 
  complete(t = seq.Date(min(t), max(t), by = "5 days"))

# Linear gap filling
ggplot(table_all) +
  aes(x = t, y = valid_pixels) + theme_minimal() + 
  geom_line() + geom_point() +
  labs(title = "Num. of valid pixels within the polygon", x = "Date",
       y = "valid_pixels")

# No gap filling --> irregular time series
ggplot(table_all_complete) +
  aes(x = t, y = valid_pixels) + theme_minimal() + 
  geom_line() + geom_point() +
  labs(title = "Num. of valid pixels within the polygon", x = "Date",
       y = "valid_pixels")
```

Do the same for some other indices.

```{r}

ggplot(table_all, aes(x = t, y = NDMI_mean)) +
  geom_line(color = "steelblue") +
  geom_point(color = "steelblue") +
  geom_errorbar(aes(ymin = NDMI_mean - NDMI_sd,
                    ymax = NDMI_mean + NDMI_sd),
                width = 0.2, color = "darkgray") +
  theme_minimal() +
  ylim(-0.3, 0.5) +  # adjust if needed
  labs(title = "NDMI with Standard Deviation",
       x = "Date",
       y = "NDMI")

ggplot(table_all_complete, aes(x = t, y = NDMI_mean)) +
  geom_line(color = "steelblue") +
  geom_point(color = "steelblue") +
  geom_errorbar(aes(ymin = NDMI_mean - NDMI_sd,
                    ymax = NDMI_mean + NDMI_sd),
                width = 0.2, color = "darkgray") +
  theme_minimal() +
  ylim(-0.3, 0.5) +  # adjust if needed
  labs(title = "NDMI with Standard Deviation",
       x = "Date",
       y = "NDMI")

ggplot(table_all, aes(x = t, y = STR_mean)) +
  geom_line(color = "steelblue") +
  geom_point(color = "steelblue") +
  geom_errorbar(aes(ymin = STR_mean - STR_sd,
                    ymax = STR_mean + STR_sd),
                width = 0.2, color = "darkgray") +
  theme_minimal() +
  labs(title = "STR with Standard Deviation",
       x = "Date",
       y = "STR")

ggplot(table_all_complete, aes(x = t, y = STR_mean)) +
  geom_line(color = "steelblue") +
  geom_point(color = "steelblue") +
  geom_errorbar(aes(ymin = STR_mean - STR_sd,
                    ymax = STR_mean + STR_sd),
                width = 0.2, color = "darkgray") +
  theme_minimal() +
  labs(title = "STR with Standard Deviation",
       x = "Date",
       y = "STR")
```

#### How to deal with missing values?

**Option 1:** use a lower cloud cover filter in pre-processing and rely on cloud masking –\> risky + cloud masks will still result in missing values.

**Option 2:** data fusion

e.g. Landsat - Sentinel 2 combined time-series

\* <https://hls.gsfc.nasa.gov/>

e.g. use Sentinel-1 data to predict values for Sentinel-2

\* <https://blog.vito.be/remotesensing/cropsar2023>

**Option 3:** data interpolation

Which interpolation should we use to fill in gaps?

*Spatial interpolation (on pixel level):*

```{r spatial_interpolation}
par(mfrow=c(1,3))

# Extract the 67th time slice
r67_stars <- slice(obj_classified, "t", 130)

r <- rast(r67_stars)

plot(r,main="2024-08-19",col=c("tan"))
plot(st_geometry(AOI),add=T)

# Apply majority (modal) filter, but only on "NA" values.
r_focal <- focal(r, w = 3, fun = modal, na.policy = "only", na.rm = TRUE)

plot(r_focal, main = "2024-08-19 (filled)", col = c("tan"))
plot(st_geometry(AOI),add=T)

AOI_buff <- st_buffer(AOI, -6)
# Mask
r_mask <- mask(r_focal,AOI_buff)

# Plot to verify
plot(r_mask, main = "2024-08-19 (masked to the original boundary)", col = c("tan"))
plot(st_geometry(AOI),add=T)

par(mfrow=c(1,1))
```

*Spatial interpolation (on plot level) –\> won't be shown.*

*Temporal interpolation (on plot level)*

```{r, class.source = 'fold-hide'}
# Ensure proper date format
water_proportion_data2 <- water_proportion_data %>%
  mutate(t = as.Date(t))

# Fill missing dates (5-day steps)
water_proportion_data_complete <- water_proportion_data2 %>%
  complete(t = seq.Date(min(t), max(t), by = "5 days"))

# Store numeric x-axis for regression-based methods
water_proportion_data_complete <- water_proportion_data_complete %>%
  mutate(t_num = as.numeric(t))

# --- Interpolation Methods ---

# Linear interpolation
water_proportion_data_complete$linear <- na.approx(
  water_proportion_data_complete$proportion_water, 
  x = water_proportion_data_complete$t_num, na.rm = FALSE
)

# LOESS interpolation
loess_fit <- loess(proportion_water ~ t_num, 
                   data = water_proportion_data_complete, 
                   span = 0.3)
water_proportion_data_complete$loess <- predict(loess_fit, 
                                                newdata = water_proportion_data_complete$t_num)

# Spline interpolation
spline_fit <- splinefun(water_proportion_data_complete$t_num, 
                        water_proportion_data_complete$proportion_water, 
                        method = "natural")
water_proportion_data_complete$spline <- spline_fit(water_proportion_data_complete$t_num)

# Smoothing spline
smooth_fit <- smooth.spline(water_proportion_data2$t, 
             water_proportion_data2$proportion_water, 
             spar = 0.3)
water_proportion_data_complete$smooth_spline <- predict(smooth_fit,                                                         water_proportion_data_complete$t_num)$y

# Kernel regression (local constant / local linear)
bw <- npregbw(proportion_water ~ t_num, data = water_proportion_data_complete)
kernel_fit <- npreg(bw)
water_proportion_data_complete$kernel <- predict(kernel_fit, 
                                                 newdata = data.frame(t_num = water_proportion_data_complete$t_num))

# Gaussian Process regression
gp_fit <- gausspr(proportion_water~t_num, 
                  data = water_proportion_data_complete, 
                  kernel = "rbfdot")
water_proportion_data_complete$gp <- predict(gp_fit, 
                                             newdata = data.frame(t_num = water_proportion_data_complete$t_num))


# --- Visualization: Compare Methods ---
water_long <- water_proportion_data_complete %>%
  select(t,  gp, linear,kernel,smooth_spline,loess,spline) %>%
  pivot_longer(-t, names_to = "method", values_to = "value")


ggplot(water_long, aes(x = t, y = value, color = method)) +
  geom_line(size = 1) +
  geom_point(data = water_proportion_data2, 
             aes(x = t, y = proportion_water), 
             color = "black", size = 2, inherit.aes = FALSE) +
  labs(
    title = "Comparison of Interpolation Techniques for Water Proportion",
    subtitle = "Black dots = observed values",
    x = "Date",
    y = "Proportion of Water Pixels"
  ) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_blank()
  ) + 
  facet_wrap(~method) # Comment this out if you want to the curves plotted on top of each other. 

```

**In my opinion:** non of the methods here shown are perfect (over- and underfitting) Further tuning of the parameters is required, or additional smoothing in case of overfitting).

*Interpolation on pixel level –\> fictive example*

```{r}
slices <- obj_classified[,,,c(69,70)]
 
# Compute mean across the time dimension
t_mean <- st_apply(slices, MARGIN = c("x", "y"), FUN = mean, na.rm = TRUE)
 
# Plot result
plot(obj_classified[,,,69], main = "t - 5 days", col = c("tan","blue"))
plot(t_mean[1], main = "t", col = c("tan", "cyan"))
plot(obj_classified[,,,70], main = "t + 5 days", col = c("tan"))

```

-   Interpolation on plot level –\> easy and quite fast

-   Interpolation on pixel level –\> computational expensive. You do however loose the spatial information.

Other more advanced interpolation technique (and dataset) –\> TSIRF algorithm: combines temporal interpolation, temporal smoothing and temporal aggregation.

\* <https://pubmed.ncbi.nlm.nih.gov/39650555/>

**Option 4:** temporal data aggregation

First, we need to decide how we will temporally aggregate the classification. You can choose in the code below between monthly, seasonally (three months) or yearly. Be aware that due to clouds we won't have an equal number of observations for each time aggregation.

The function we use is the "maximum", indicating if a pixel was inundated within the time interval (month, season, year), it will be returned as inundated.

**Question 5: What are the advantages and disadvantages of using the min/max aggregation function? When would you use it?**

-   Monthly temporal aggregation

```{r, class.source = 'fold-hide'}
# Extract classes into a tibble
classified_df <- as_tibble(obj_classified[AOI])

# Add a month column
classified_df <- classified_df %>%
  mutate(month = floor_date(t, "month"))

# Compute max and median classified value per pixel per month
classified_df_monthly_max <- classified_df %>%
  group_by(month, x, y) %>%      # group by pixel location + month
  summarize(Class = max(X, na.rm = TRUE), .groups = "drop")

classified_df_monthly_median <- classified_df %>%
  group_by(month, x, y) %>%      # group by pixel location + month
  summarize(Class = median(X, na.rm = TRUE), .groups = "drop")

# Convert -Inf values to NA
classified_df_monthly_max[classified_df_monthly_max == -Inf] <- NA
classified_df_monthly_median[classified_df_monthly_median == -Inf] <- NA

# Convert back to stars
classified_monthly_max <- st_as_stars(classified_df_monthly_max, dims = c("x", "y", "month"))

classified_monthly_median <- st_as_stars(classified_df_monthly_median, dims = c("x", "y", "month"))

# Convert the stars object to factor using st_set_dimensions
classified_monthly_max_factor <- classified_monthly_max
classified_monthly_max_factor[[1]] <- factor(
  classified_monthly_max_factor[[1]],
  levels = c(1, 2),
  labels = pred_levels
)

classified_monthly_median_factor <- classified_monthly_median
classified_monthly_median_factor[[1]] <- factor(
  classified_monthly_median_factor[[1]],
  levels = c(1, 1.5, 2),
  labels = c("dry","moist","water")
)

# Plot with discrete scale
ggplot() +
  ggtitle("Monthly Max class. (Jussila)") + 
  geom_stars(data = classified_monthly_max_factor) +
  geom_sf(data = AOI, fill = NA, color = "red", linewidth = 1) +
  facet_wrap(~month,ncol=15) +
  theme_minimal() +
  theme(axis.text = element_blank(),          # remove axis tick labels
    axis.ticks = element_blank(),         # remove tick marks
    )+
  scale_fill_manual(
    name = "Class",
    values = c("dry" = "tan", "water" = "blue")
  )

ggplot() +
  ggtitle("Monthly Median class. (Jussila)") + 
  geom_stars(data = classified_monthly_median_factor) +
  geom_sf(data = AOI, fill = NA, color = "red", linewidth = 1) +
  facet_wrap(~month,ncol=15) +
  theme_minimal() +
  theme(axis.text = element_blank(),          # remove axis tick labels
    axis.ticks = element_blank(),         # remove tick marks
    )+
  scale_fill_manual(
    name = "Class",
    values = c("dry" = "tan", "moist" = "cyan", "water" = "blue")
  )
```

Calculate now the % of inundation (so spatial aggregation to plot level).

For max aggregation:
```{r, class.source = 'fold-hide'}
# For max aggregation

# Calculate the proportion of "water" pixels for each time stamp and visualize
# Convert the classified stars object to a tibble
st_crs(classified_monthly_max) <- st_crs(AOI)
classified_monthly_max_pixels <- as_tibble(classified_monthly_max[AOI])

# Rename the column for clarity and filter out NA values
names(classified_monthly_max_pixels)[which(names(classified_monthly_max_pixels) == "X")] <- "Class"

monthly_classified_max_pixels <- classified_monthly_max_pixels %>% dplyr::filter(!is.na(Class))

# Calculate total pixels and water pixels for each time step
monthly_max_water_proportion_data <- monthly_classified_max_pixels %>%
  group_by(month) %>%
  summarize(
    total_pixels = n(),
    water_pixels = sum(Class == 2, na.rm = TRUE), # Class 2 is 'water'
    .groups = "drop"
  ) %>%
  mutate(
    proportion_water = water_pixels / total_pixels
  )

# Print the resulting tibble with proportions
print(monthly_max_water_proportion_data)

# Visualize the time series of water proportion
ggplot(monthly_max_water_proportion_data, aes(x = month, y = proportion_water)) +
  geom_line(color = "blue", size = 1.2) +
  geom_point(color = "blue", size = 2) +
  labs(
    title = "Proportion of Inundated Pixels Over Time (monthly max.)",
    subtitle = "Within the selected habitat polygon boundary",
    x = "Date",
    y = "Proportion of Water Pixels"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )

```

For median aggregation:
```{r, class.source = 'fold-hide'}
# For median aggregation --> consider the pixels values as "discrete".

# Calculate the proportion of "water" and "moist" pixels for each time stamp and visualize
# Convert the classified stars object to a tibble
st_crs(classified_monthly_median) <- st_crs(AOI)
classified_monthly_median_pixels <- as_tibble(classified_monthly_median[AOI])

# Rename the column for clarity and filter out NA values
names(classified_monthly_median_pixels)[which(names(classified_monthly_median_pixels) == "X")] <- "Class"

monthly_classified_median_pixels <- classified_monthly_median_pixels %>% dplyr::filter(!is.na(Class))

# Calculate total pixels and water pixels for each time step
monthly_median_water_proportion_data <- monthly_classified_median_pixels %>%
  group_by(month) %>%
  summarize(
    total_pixels = n(),
    water_pixels = sum(Class == 2, na.rm = TRUE), # Class 2 is 'water'
    moist_pixels = sum(Class == 1.5, na.rm =TRUE), #Class 1.5 is 'moist'
    .groups = "drop"
  ) %>%
  mutate(
    proportion_water = water_pixels / total_pixels,
    proportion_moist = moist_pixels / total_pixels,
  )

# Print the resulting tibble with proportions
print(monthly_median_water_proportion_data)


# Visualize both water and moist proportions over time
ggplot(monthly_median_water_proportion_data, aes(x = month)) +
  geom_line(aes(y = proportion_water, color = "Water"), size = 1.2) +
  geom_point(aes(y = proportion_water, color = "Water"), size = 2) +
  geom_line(aes(y = proportion_moist, color = "Moist"), size = 1.2, linetype = "dashed") +
  geom_point(aes(y = proportion_moist, color = "Moist"), size = 2) +
  labs(
    title = "Proportion of Inundated and Moist Pixels Over Time (monthly median)",
    subtitle = "Within the selected habitat polygon boundary",
    x = "Date",
    y = "Proportion of Pixels",
    color = "Class"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_color_manual(values = c("Water" = "blue", "Moist" = "cyan")) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 10)
  )

```

Reshape data for stacked plotting
```{r, class.source = 'fold-hide'}
# Reshape data for stacked plotting
monthly_median_long <- monthly_median_water_proportion_data %>%
  select(month, proportion_water, proportion_moist) %>%
  tidyr::pivot_longer(
    cols = starts_with("proportion_"),
    names_to = "Class",
    values_to = "Proportion"
  ) %>%
  mutate(
    Class = recode(Class,
                   proportion_water = "Water",
                   proportion_moist = "Moist")
  )

# Print the resulting tibble with proportions
print(monthly_median_long)

# Create stacked area chart
ggplot(monthly_median_long, aes(x = month, y = Proportion, fill = Class)) +
  geom_area(position = "stack", alpha = 0.8) +
  geom_line(position = "stack", color = "black", size = 0.2, alpha = 0.4) +
  labs(
    title = "Stacked Proportion of Moist and Inundated Pixels Over Time (monthly median)",
    subtitle = "Within the selected habitat polygon boundary",
    x = "Date",
    y = "Proportion of Pixels",
    fill = "Class"
  ) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = c("Water" = "blue", "Moist" = "skyblue3")) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 10)
  )

```

For median aggregation, when pixels are considered as "continuous" instead of "catagorical".
```{r, class.source = 'fold-hide'}
# For median aggregation --> consider the pixels as "continuous".

# Calculate the average pixel value for each time step
monthly_median_water_proportion_data2 <- monthly_classified_median_pixels %>%
  group_by(month) %>%
  mutate(
    proportion_water = mean(Class, na.rm = TRUE),
  )

# Print the resulting tibble with proportions
print(monthly_median_water_proportion_data2)


# Visualize both water and moist proportions over time
ggplot(monthly_median_water_proportion_data2, aes(x = month,y = proportion_water)) +
  geom_line(,size = 1.2) +
  geom_point(size = 2) +
    labs(
    title = "Proportion of Inundated and Moist Pixels Over Time (monthly median)",
    subtitle = "Within the selected habitat polygon boundary",
    x = "Date",
    y = "Proportion of Pixels",
    color = "Class"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 10)
  )
```

Again - compare with the missing data:

```{r, class.source = 'fold-hide'}
# Adapt the plot, to see the monthly gaps within the time-series
# Create a complete sequence of months covering the full range
all_months <- tibble(month = seq(min(monthly_max_water_proportion_data$month),
                                 max(monthly_max_water_proportion_data$month),
                                 by = "1 month"))

# Fill missing months with NA
plot_data <- all_months %>%
  left_join(monthly_max_water_proportion_data, by = "month")

# --- Identify missing stretches ---
missing_info <- plot_data %>%
  mutate(is_missing = is.na(proportion_water),
         gap_id = cumsum(!is_missing)) %>%
  dplyr::filter(is_missing) %>%
  group_by(gap_id) %>%
  summarise(start = min(month), end = max(month), .groups = "drop")

# Split into multi-month gaps vs single missing months
missing_multi <- missing_info %>%
  dplyr::filter(start != end) %>%
  mutate(end = end + 30)   # extend end by ~1 month for shading

missing_single <- missing_info %>%
  dplyr::filter(start == end)

# --- Plot ---
ggplot(plot_data, aes(x = month, y = proportion_water)) +
  # Shaded missing ranges
  geom_rect(data = missing_multi,
            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),
            inherit.aes = FALSE,
            fill = "grey80", alpha = 0.5) + # gray zones for multiple missing months
  # Red dotted lines for isolated missing months
  geom_vline(data = missing_single,
             aes(xintercept = as.numeric(start)),
             color = "red", linetype = "dotted", size = 1) + # red lines for one missing month
  # Actual time series
  geom_line(color = "blue", size = 1.2, na.rm = FALSE) +
  geom_point(color = "blue", size = 2, na.rm = TRUE) +
  labs(
    title = "Proportion of Inundated Pixels Over Time (monthly max.)",
    subtitle = "Within the selected habitat polygon boundary",
    x = "Date",
    y = "Proportion of Water Pixels"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = percent_format()) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

(ignore) Add a seasonal trend. Be aware that the time series is rather short to do a read 'trend' analysis and that the trend is prone to missing data and "false predictions" by the model. *–\> we won't do this in the workshop.*

```{r, eval = FALSE, echo = FALSE}
# # Add seasonal trends:
# # Add a 'season' column to the water_proportion_data
# monthly_water_proportion_data <- monthly_water_proportion_data %>%
#   mutate(
#     month2 = month(month),
#     season = case_when(
#       month2 %in% 1:3 ~ "Winter",
#       month2 %in% 4:6 ~ "Spring",
#       month2 %in% 7:9 ~ "Summer",
#       month2 %in% 10:12 ~ "Autumn"
#     )
#   )
# 
# 
# # Plot with scatter points and regression lines by season
# ggplot(monthly_water_proportion_data, aes(x = month, y = proportion_water, color = season)) +
#   geom_point(size = 2) +  # Scatter points
#   geom_smooth(method = "lm", se = FALSE, linetype = "solid", size = 1) + # Linear regression per season
#   labs(
#     title = "Proportion of Inundated Pixels Over Time (monthly max.) by Season",
#     subtitle = "Within the selected habitat polygon boundary",
#     x = "Date",
#     y = "Proportion of Water Pixels",
#     color = "Season"
#   ) +
#   theme_minimal() +
#   scale_y_continuous(labels = scales::percent_format()) +
#   theme(
#     plot.title = element_text(hjust = 0.5, face = "bold"),
#     plot.subtitle = element_text(hjust = 0.5),
#     axis.title = element_text(size = 12),
#     axis.text = element_text(size = 10)
#   )
```

-   Seasonal (3 months) temporal aggregation (optional)

```{r, class.source = 'fold-hide'}
classified_df <- as_tibble(obj_classified[AOI])

# Add a season column (Winter, Spring, Summer, Autumn + year)
classified_df <- classified_df %>%
  mutate(
    season_start = floor_date(t, "quarter"),
    year = year(season_start),
    quarter = quarter(season_start),
    season = case_when(
      quarter == 1 ~ "Winter",
      quarter == 2 ~ "Spring",
      quarter == 3 ~ "Summer",
      quarter == 4 ~ "Autumn"
    ),
    # ordered factor for correct sorting
    season = factor(season, levels = c("Winter", "Spring", "Summer", "Autumn"), ordered = TRUE),
    season_label = paste0(season, " ", year)
  )

# Ensure season_label is ordered correctly (by year + season order)
classified_df <- classified_df %>%
  arrange(year, season) %>%
  mutate(season_label = factor(season_label, levels = unique(season_label)))

# Compute max classified value per pixel per season
classified_df_seasonal <- classified_df %>%
  group_by(season_label, x, y) %>%
  summarize(Class = max(X, na.rm = TRUE), .groups = "drop")

# Convert -Inf values to NA
classified_df_seasonal[classified_df_seasonal == -Inf] <- NA

# Convert back to stars
classified_seasonal <- st_as_stars(classified_df_seasonal, dims = c("x", "y", "season_label"))

# Convert to factor
classified_seasonal_factor <- classified_seasonal
classified_seasonal_factor[[1]] <- factor(
  classified_seasonal_factor[[1]],
  levels = c(1, 2),
  labels = pred_levels
)

# Plot with discrete scale and season labels
ggplot() +
  ggtitle("Seasonal Max class. (Jussila)") + 
  geom_stars(data = classified_seasonal_factor) +
  geom_sf(data = AOI, fill = NA, color = "red", linewidth = 1) +
  facet_wrap(~season_label, ncol=4) +
  theme_minimal() +
  theme(axis.text = element_blank(),          # remove axis tick labels
    axis.ticks = element_blank(),         # remove tick marks
    ) +
  scale_fill_manual(
    name = "Class",
    values = c("dry" = "tan", "water" = "blue")
  )

```

```{r, class.source = 'fold-hide'}
# Calculate proportion of "water" pixels for each season
st_crs(classified_seasonal) <- st_crs(AOI)
classified_seasonal_pixels <- as_tibble(classified_seasonal[AOI])

names(classified_seasonal_pixels)[which(names(classified_seasonal_pixels) == "X")] <- "Class"
seasonal_classified_pixels <- classified_seasonal_pixels %>% dplyr::filter(!is.na(Class))

seasonal_water_proportion_data <- seasonal_classified_pixels %>%
  group_by(season_label) %>%
  summarize(
    total_pixels = n(),
    water_pixels = sum(Class == 2, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    proportion_water = water_pixels / total_pixels
  )

print(seasonal_water_proportion_data)

# Plot time series with labeled seasons
ggplot(seasonal_water_proportion_data, aes(x = season_label, y = proportion_water, group = 1)) +
  geom_line(color = "blue", size = 1.2) +
  geom_point(color = "blue", size = 2) +
  labs(
    title = "Proportion of Inundated Pixels Over Time",
    subtitle = "Within the selected habitat polygon boundary (seasonal aggregation)",
    x = "Season",
    y = "Proportion of Water Pixels"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text.x = element_text(size = 10, angle = 45, hjust = 1)
  )
```

-   Yearly temporal aggregation (optional)

```{r, class.source = 'fold-hide'}
# Add a month column
classified_df_y <- classified_df %>%
  mutate(month = floor_date(t, "year"))

# Compute max classified value per pixel per month
classified_df_yearly <- classified_df_y %>%
  group_by(year, x, y) %>%      # group by pixel location + month
  summarize(Class = max(X, na.rm = TRUE), .groups = "drop")

# Convert -Inf values to NA
classified_df_yearly[classified_df_yearly == -Inf] <- NA

# Convert back to stars
classified_yearly <- st_as_stars(classified_df_yearly, dims = c("x", "y", "year"))

# Convert the stars object to factor using st_set_dimensions
classified_yearly_factor <- classified_yearly
classified_yearly_factor[[1]] <- factor(
  classified_yearly_factor[[1]],
  levels = c(1, 2),
  labels = pred_levels
)

# Plot with discrete scale
ggplot() +
  ggtitle("yearly Max class. (Jussila)") + 
  geom_stars(data = classified_yearly_factor) +
  geom_sf(data = AOI, fill = NA, color = "red", linewidth = 1) +
  facet_wrap(~year) +
  theme_minimal() +
  scale_fill_manual(
    name = "Class",
    values = c("dry" = "tan", "water" = "blue")
  )

```

```{r, class.source = 'fold-hide'}
# Calculate the proportion of "water" pixels for each time stamp and visualize
# Convert the classified stars object to a tibble
st_crs(classified_yearly) <- st_crs(AOI)
classified_yearly_pixels <- as_tibble(classified_yearly[AOI])

# Rename the column for clarity and filter out NA values
names(classified_yearly_pixels)[which(names(classified_yearly_pixels) == "X")] <- "Class"
yearly_classified_pixels <- classified_yearly_pixels %>% dplyr::filter(!is.na(Class))

# Calculate total pixels and water pixels for each time step
yearly_water_proportion_data <- yearly_classified_pixels %>%
  group_by(year) %>%
  summarize(
    total_pixels = n(),
    water_pixels = sum(Class == 2, na.rm = TRUE), # Class 2 is 'water'
    .groups = "drop"
  ) %>%
  mutate(
    proportion_water = water_pixels / total_pixels
  )

# Print the resulting tibble with proportions
print(yearly_water_proportion_data)

# Visualize the time series of water proportion
ggplot(yearly_water_proportion_data, aes(x = year, y = proportion_water)) +
  geom_line(color = "blue", size = 1.2) +
  geom_point(color = "blue", size = 2) +
  labs(
    title = "Proportion of Inundated Pixels Over Time",
    subtitle = "Within the selected habitat polygon boundary",
    x = "Date",
    y = "Proportion of Water Pixels"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

## Pipelines

### Tytti's pipeline

-   Bi-weekly temporal aggregation

```{r, class.source = 'fold-hide'}
## Temporal aggregation: 2weekly median value with customized approach
# generate 2-week breaks for the observed years
time_vals <- st_get_dimension_values(obj_wetness, "t")
start <- floor_date(min(time_vals), "month")
end   <- ceiling_date(max(time_vals), "month")
# All 1st and 15th of each month between start and end
breaks <- sort(c(seq(start, end, by = "1 month"),
                 seq(start + days(14), end, by = "1 month")))


# Aggregate using 2-week intervals
obj_2week <- aggregate(obj_wetness, by = breaks, FUN = median, na.rm = TRUE)

# Summarise 2-weekly  
table_2w <- 
  obj_2week[,,,] |>   
  as_tibble() |>
  group_by(time) |> 
  summarize(inundation = mean(Juss_cl, na.rm = TRUE)*100, 
            inundation_Wiw = mean(Wiw_cl, na.rm = TRUE)*100,
            NDMI = mean(NDMI, na.rm=T), #Ranges from -1 to +1, where the lowest values indicate low vegetation water content, and the highest ones correspond to high water content
            NDWI = mean(NDWI, na.rm=T), #Over 0.2: water. Below 0: non-water
            NDPI = mean(NDPI, na.rm=T), # scores above a certain high value, e.g., larger than 0.75, indicates a pond area with good water quality
            STR = mean(STR, na.rm=T), # Higher values, higher soil moisture content
            B11 = mean(B11, na.rm=T)) # lower values, higher moisture. 

table_2w_plotting <- table_2w[!is.na(table_2w$inundation),] # drop NAs for plotting

ggplot(table_2w_plotting) + ## check the dates in table to plot a specific single year 
  aes(x = time, y = inundation) + 
  ylim(0,100) +
  geom_line() + geom_point() +
  labs(title = "Inundated area %",
       x = "Date",
       y = "Inundated area (%)") +
  theme_minimal()

ggplot(table_2w_plotting) +
  aes(x = time, y = STR) + 
  #ylim(1,5) +
  geom_line() + geom_point() +
  labs(title = "STR",
       x = "Date",
       y = "STR") +
  theme_minimal()
```

The time series is still irregular. We will use linear interpolation for gap filling.

```{r, class.source = 'fold-hide'}
# extract 2-weekly time points
time_vals2w <- st_get_dimension_values(obj_2week, "time")

# interpolate NA values along time dimension
obj_filled_2w <- st_apply(
  obj_2week,
  MARGIN = c("x", "y"),   
  FUN = function(ts) { # repeat interpolation function over each pixel time series
    if (all(is.na(ts))) { # keep NA time series as NA outside site polygon
      return(ts)  
    }
    approx( # interpolate missing time points
      x = as.numeric(time_vals2w),
      y = ts,
      xout = as.numeric(time_vals2w),
      method = "linear",
      rule = 2
    )$y
  },.fname = "time"
)
# fix the broken time dimension in output
obj_filled_2w <- st_set_dimensions(obj_filled_2w, "time", values = time_vals2w)

ggplot() +
     ggtitle("2-weekly mean class (Jussila)") +
     geom_stars(data = obj_filled_2w["Juss_cl"]) +
     geom_sf(data = AOI, fill = NA, color = "red", linewidth = 1) +
     facet_wrap(~time,ncol=20) +
     theme_minimal() +
     theme(axis.text = element_blank(),          # remove axis tick labels
     axis.ticks = element_blank(),         # remove tick marks
     ) +
     scale_fill_gradientn(
         name = "Wetness",
         colors = c("tan", "cyan", "blue"),
         na.value = "gray",
         limits = c(0, 1)
     )

# Plot 2-week time series (gapfilled)
# first summarise for site area:
table_gf2w <- # Gapfilled 2-weekly table
  obj_filled_2w[,,,] |>  
  as_tibble() |>
  group_by(time) |> 
  summarize(inundation = mean(Juss_cl, na.rm = TRUE)*100,
            inundation_Wiw = mean(Wiw_cl, na.rm = TRUE)*100,
            NDMI = mean(NDMI, na.rm=T), #Ranges from -1 to +1, where the lowest values indicate low vegetation water content, and the highest ones correspond to high water content
            NDWI = mean(NDWI, na.rm=T), #Over 0.2: water. Below 0: non-water
            NDPI = mean(NDPI, na.rm=T), # scores above a certain high value, e.g., larger than 0.75, indicates a pond area with good water quality
            STR = mean(STR, na.rm=T), # Higher values, higher soil moisture content
            B11 = mean(B11, na.rm=T)) # lower values, higher moisture. 
# New column: Flag gapfilled values
table_gf2w$gapfilled <- "2w median"
table_gf2w$gapfilled[is.na(table_2w$B11)] <- "gapfilled"
table_gf2w$gapfilled <- as.factor(table_gf2w$gapfilled)
# time format to Date for plotting
table_gf2w$date <- as.Date(table_gf2w$time) 


ggplot(table_gf2w) + #check the dates in table to plot a single year ([65:74,] -> 2018 in this case)
  aes(x = date, y = inundation) + scale_x_date(date_labels = "%b %y") + 
  geom_line() + geom_point(aes(colour = gapfilled), size=2) + 
  scale_color_manual(values = c("gapfilled" = "red", "2w median" = "black"), name=NULL)+
  labs(title = "Inundation %",x = "Date", 
       y = "Inundated area (%)") +
  ylim(0,100)+
  theme_minimal()


ggplot(table_gf2w) +
  aes(x = date, y = STR) +  scale_x_date(date_labels = "%b %y") + 
  geom_line() + geom_point(aes(colour = gapfilled), size=2) +
  scale_color_manual(values = c("gapfilled" = "red", "2w median" = "black"), name=NULL)+
  labs(title = "STR", x = "Date", 
       y = "STR") + 
  #ylim(1,5)+ # adjust if needed
  theme_minimal()

ggplot(table_gf2w) +
  aes(x = date, y = NDMI) +  scale_x_date(date_labels = "%b %y") + 
  geom_line() + geom_point(aes(colour = gapfilled), size=2) +
  scale_color_manual(values = c("gapfilled" = "red", "2w median" = "black"), name=NULL)+
  labs(title = "NDMI", x = "Date", 
       y = "NDMI") + 
  ylim(-0.1, 0.55)+ # adjust if needed
  theme_minimal()

ggplot(table_gf2w) +
  aes(x = date, y = -B11) +  scale_x_date(date_labels = "%b %y") + 
  geom_line() + geom_point(aes(colour = gapfilled), size=2) +
  scale_color_manual(values = c("gapfilled" = "red", "2w median" = "black"), name=NULL)+
  labs(title = "SWIR",x = "Date",
       y = "B11 (neg)") + # plot SWIR as negation for comparability (low SWIR, high moisture. Opposite to other indicators)
  #ylim(-2500, -800)+ # adjust if needed
  theme_minimal()

```

Plotting yearly indicators.

```{r, class.source = 'fold-hide'}
# Using 2-weekly gapfilled stars object to calculate statistics

# aggregate stars into yearly layers
## Mean (for each pixel?)
obj_y_mean <- aggregate(obj_filled_2w, by = "year", 
                        FUN=mean, na.rm=T) 
## Min (for each pixel?)
obj_y_min <- aggregate(obj_filled_2w, by = "year", 
                       FUN=min, na.rm=T) # returns Inf for NA areas
obj_y_min[obj_y_min == Inf] <- NA # convert Inf back to NA
## Max (for each pixel?)
obj_y_max <- aggregate(obj_filled_2w, by = "year", 
                       FUN=max, na.rm=T) # returns -Inf for NA areas
obj_y_max[obj_y_max == -Inf] <- NA # convert -Inf back to NA


## Plot yearly raster maps

# SWIR [7], inundation Jussila [14], inundation Wiw [16], NDMI = [10], NDWI = [11], NDPI = [12], STR = [13]

# Inundation (Jussila). Inundated % of time
plot(obj_y_mean[14], col = viridis(100, option = "D", direction=-1),
     breaks = seq(0, 1, length.out = 101))  
# Inundation (Wiw). Inundated % of time
plot(obj_y_mean[16], col = viridis(100, option = "D", direction=-1),
     breaks = seq(0, 1, length.out = 101)) 
# STR
plot(obj_y_mean[13], col = viridis(100, option = "D", direction=-1),
     breaks = seq(0, 40, length.out = 101))  
# NDMI
plot(obj_y_mean[10], col = viridis(100, option = "D", direction= -1),
     breaks = seq(min(obj_y_mean[[10]], na.rm=T), 
                  max(obj_y_mean[[10]], na.rm=T), length.out = 101)) 

```

Plotting yearly indicators for site area:

```{r, class.source = 'fold-hide'}
# MEAN - summarise values for site area
table_y_mean <- 
  obj_y_mean[,,,] |> 
  as_tibble() |>
  group_by(time) |> 
  summarize(inundation = mean(Juss_cl, na.rm = TRUE)*100,
            inundation_Wiw = mean(Wiw_cl, na.rm = TRUE)*100,
            NDMI = mean(NDMI, na.rm=T), #Ranges from -1 to +1, where the lowest values indicate low vegetation water content, and the highest ones correspond to high water content
            NDWI = mean(NDWI, na.rm=T), #Over 0.2: water. Below 0: non-water
            NDPI = mean(NDPI, na.rm=T), # scores above a certain high value, e.g., larger than 0.75, indicates a pond area with good water quality
            STR = mean(STR, na.rm=T), # Higher values, higher soil moisture content
            B11 = mean(B11, na.rm=T)) # lower values, higher moisture. 

#summarise min for sites (site mean at minimum wet situation)
table_y_min <- 
  obj_y_min[,,,] |> 
  as_tibble() |>
  group_by(time) |> 
  summarize(inundation = mean(Juss_cl, na.rm = TRUE)*100,
            inundation_Wiw = mean(Wiw_cl, na.rm = TRUE)*100,
            NDMI = mean(NDMI, na.rm=T), #Ranges from -1 to +1, where the lowest values indicate low vegetation water content, and the highest ones correspond to high water content
            NDWI = mean(NDWI, na.rm=T), #Over 0.2: water. Below 0: non-water
            NDPI = mean(NDPI, na.rm=T), # scores above a certain high value, e.g., larger than 0.75, indicates a pond area with good water quality
            STR = mean(STR, na.rm=T), # Higher values, higher soil moisture content
            B11 = mean(B11, na.rm=T)) # lower values, higher moisture. 
# for SWIR, wetness minimum is SWIR max value. 

#summarise max for sites (site mean at minimum wet situation)
table_y_max <- 
  obj_y_max[,,,] |>  
  as_tibble() |>
  group_by(time) |> 
  summarize(inundation = mean(Juss_cl, na.rm = TRUE)*100,
            inundation_Wiw = mean(Wiw_cl, na.rm = TRUE)*100,
            NDMI = mean(NDMI, na.rm=T), #Ranges from -1 to +1, where the lowest values indicate low vegetation water content, and the highest ones correspond to high water content
            NDWI = mean(NDWI, na.rm=T), #Over 0.2: water. Below 0: non-water
            NDPI = mean(NDPI, na.rm=T), # scores above a certain high value, e.g., larger than 0.75, indicates a pond area with good water quality
            STR = mean(STR, na.rm=T), # Higher values, higher soil moisture content
            B11 = mean(B11, na.rm=T)) # lower values, higher moisture.
# for SWIR, wetness maximum is SWIR min value.


# plot all yearly stats in one graph: Mean and shaded range between min-max
# STR
ggplot() +
  #ylim(1,5)+ # adjust if needed
  #geom_line(data= table_gf2w, aes(x = time - months(6), y = STR), color="grey") + # full time series to background?
  geom_line(data= table_y_mean, aes(x = time, y = STR)) + 
  geom_point(data= table_y_mean, aes(x = time, y = STR)) + 
  geom_ribbon(aes(x = table_y_mean$time, 
                  ymin = table_y_min$STR, 
                  ymax = table_y_max$STR),fill="#1f9e89", alpha= 0.2)+ 
  labs(title = "STR moisture mean and range (min, max)",
       x = "Year",
       y = "STR") +
  theme_minimal() + theme(legend.position="none")

# NDMI
ggplot() +
  #ylim(-0.1,0.5)+ # adjust if needed
  #geom_line(data= table_gf2w, aes(x = time - months(6), y = NDMI), color="grey") + # full time series to background?
  geom_line(data= table_y_mean, aes(x = time, y = NDMI)) + 
  geom_point(data= table_y_mean, aes(x = time, y = NDMI)) + 
  geom_ribbon(aes(x = table_y_mean$time, 
                  ymin = table_y_min$NDMI, 
                  ymax = table_y_max$NDMI),fill="#1f9e89", alpha= 0.2)+ 
  labs(title = "NDMI moisture mean and range (min, max)",
       x = "Year",
       y = "NDMI") +
  theme_minimal() + theme(legend.position="none")



# plot percentage of permanently and seasonally wet area. 
# Jussila model
ggplot() +
  ylim(0,100)+ 
  geom_ribbon(aes(x = table_y_mean$time, # permanent
                  ymin = 0, 
                  ymax = table_y_min$inundation),fill="#1f9e89", alpha= 0.6)+ 
  geom_ribbon(aes(x = table_y_mean$time, # seasonal
                  ymin = table_y_min$inundation, 
                  ymax = table_y_max$inundation),fill="#6ece58", alpha= 0.3)+  #Temporarily inundated
  geom_ribbon(aes(x = table_y_mean$time, # never
                  ymin = table_y_max$inundation, 
                  ymax = 100),fill="#fde725", alpha= 0.2)+ # Never inundated
  labs(title = "Permanently and seasonally inundated area (Jussila model)",
       x = "Year",
       y = "Inundated area %") +
  theme_minimal() + theme(legend.position="none") # + scale_x_date(date_breaks = "1 year")


# Lefebvre Wiw model
ggplot() +
  ylim(0,100)+ 
  geom_ribbon(aes(x = table_y_mean$time, # permanent
                  ymin = 0, 
                  ymax = table_y_min$inundation_Wiw),fill="#1f9e89", alpha= 0.6)+ 
  geom_ribbon(aes(x = table_y_mean$time, # seasonal
                  ymin = table_y_min$inundation_Wiw, 
                  ymax = table_y_max$inundation_Wiw),fill="#6ece58", alpha= 0.3)+ 
  geom_ribbon(aes(x = table_y_mean$time, # never
                  ymin = table_y_max$inundation_Wiw, 
                  ymax = 100),fill="#fde725", alpha= 0.2)+ 
  labs(title = "Permanently and seasonally inundated area (Lefebvre Wiw)",
       x = "Year",
       y = "Inundated area %") +
  theme_minimal() + theme(legend.position="none") # + scale_x_date(date_breaks = "1 year")
```

### Sebastiaan's pipeline (modified Tytti's pipeline)

1.  Uncertainty evaluation.

```{r, class.source = 'fold-hide'}
# Assuming your object is named obj_classified and has a time dimension "t"
st <- obj_classified[AOI]

# 1. Extract time dimension
t_existing <- st_get_dimension_values(st, "t")

# 2. Create complete 5-day sequence
t_full <- seq(min(t_existing), max(t_existing), by = "5 days")

# 3. Find missing dates
t_missing <- setdiff(t_full, t_existing)

# 4. Proceed only if there are missing timestamps
if (length(t_missing) > 0) {
  
  # --- Template Creation: Clean Reset of Time Dimension ---
  
  # Take the first time slice, retaining all 4 dimensions (x, y, band, t)
  template <- st[,,,1, drop = FALSE]
  
  # Replace data with NA
  template[[1]][] <- NA
  
  # Define a dummy date placeholder, ensuring it's a POSIXct object
  dummy_date <- min(t_existing) - as.difftime(1, units = "days")
  dummy_date <- as.POSIXct(dummy_date)
  
  #Reset the time dimension of the template using st_set_dimensions.
  # This overwrites the existing dimension value and ensures the internal structure 
  # of the dimension object remains valid (e.g., handles "intervals" properties).
  template <- st_set_dimensions(
    template, 
    "t", 
    values = dummy_date, 
    # Also reset the point flag to FALSE for consistency if using intervals
    point = FALSE 
  )

  # --- Creating and Assigning Missing Layers ---
  
  # Create a list of new layers for missing timestamps
  missing_layers <- lapply(t_missing, function(tt) {
    new_layer <- template
    
    # Set the correct missing date 'tt' (overwriting the dummy_date)
    # The crucial fix from previous steps: assign the result back
    new_layer <- st_set_dimensions(new_layer, "t", values = tt)
    
    return(new_layer)
  })
  
  # --- Combining Layers ---
  
  # Prepare the full list of objects to combine
  all_layers_to_combine <- c(list(st), missing_layers)
  
  # Combine all layers along the time dimension
  # This uses the c.stars method correctly by unpacking the list
  st_full <- do.call(c, c(all_layers_to_combine, along = "t"))
  
  # --- Final Sort (To Interleave the NA layers and resolve stacking) ---
  
  # Sort the time dimension chronologically. 
  t_values_full <- st_get_dimension_values(st_full, "t")
  sorted_indices <- order(t_values_full)
  
  # Reorder the object data by subsetting with the sorted time indices
  st_full <- st_full[,,, sorted_indices, drop = FALSE]
  
  # Ensure the dimension values are also updated to the sorted order
  st_full <- st_set_dimensions(
    st_full,
    "t",
    values = sort(t_values_full)
  )
  
} else {
  st_full <- st
}

# Result
st_full

st_ones_alt <- st_full
st_ones_alt[[1]][!is.na(st_ones_alt[[1]])] <- 1
st_ones_alt[[1]][is.na(st_ones_alt[[1]])] <- NA # Ensure NA remains NA (as the first method does)

# Aggregate st_full by month, calculating the mean over each month.
# FUN = mean calculates the sum and divides by the number of non-NA dates in the month.
st_monthly_sum <- aggregate(
  st_ones_alt,
  by = "months",
  FUN = sum,
  na.rm = TRUE
)

ggplot() +
  ggtitle("sum of valid pixels per month") + 
  geom_stars(data = st_monthly_sum) +
  geom_sf(data = AOI, fill = NA, color = "red", linewidth = 1) +
  facet_wrap(~time,ncol=12) +
  theme_minimal() +
  theme(axis.text = element_blank(),          # remove axis tick labels
    axis.ticks = element_blank(),         # remove tick marks
    )+
     scale_fill_gradientn(
         name = "X",
         colors = c("white", "purple","darkblue"),
         na.value = "gray",
         #limits = c(0, 1)
     )
```

2.  Spatial interpolation (3x3 kernel, majority voting)

```{r, class.source = 'fold-hide'}
# --- STEP 1: Extract Spatial Template ---
# The function needs the extent and CRS to turn the plain array data back into a SpatRaster.
# Slice the first time step and convert it to a SpatRaster to get the template metadata.
# template raster for extent and CRS
r_template <- rast(slice(obj_classified, "t", 1))
template_crs <- crs(r_template, proj=TRUE)
template_extent <- ext(r_template)

# function to process a single slice
focal_na_fill_modal <- function(x_slice) {
  r_slice <- rast(t(x_slice))           # transpose first
  ext(r_slice) <- template_extent
  crs(r_slice) <- template_crs
  
  r_focal <- focal(
    r_slice,
    w = 3,
    fun = modal,
    na.policy = "only",
    na.rm = TRUE
  )
  
  as.matrix(r_focal) |> t()             # transpose back
}

# Apply across time
obj_focal_filled <- st_apply(obj_classified, MARGIN = "t", FUN = focal_na_fill_modal) 

st_dimensions(obj_focal_filled)
st_dimensions(obj_classified)

obj_focal_filled <-
  obj_focal_filled |>
  st_crop(AOI)

plot(obj_classified)
plot(obj_focal_filled)

```

3.  Temporal aggregation (median value per month).

```{r, class.source = 'fold-hide'}
# Extract classes into a tibble
obj_focal_filled <- obj_focal_filled - 1 # convert 1-2 to 0-1
classified_df_filled <- as_tibble(obj_focal_filled[AOI])

# Add a month column
classified_df_filled <- classified_df_filled %>%
  mutate(month = floor_date(t, "month"))


classified_df_filled_monthly_median <- classified_df_filled %>%
  group_by(month, x, y) %>%      # group by pixel location + month
  summarize(Class = median(X, na.rm = TRUE), .groups = "drop")

# Convert -Inf values to NA
classified_df_filled_monthly_median[classified_df_filled_monthly_median == -Inf] <- NA

# Convert back to stars
classified_filled_monthly_median <- st_as_stars(classified_df_filled_monthly_median, dims = c("x", "y", "month"))
plot(classified_filled_monthly_median)
```

4.  Temporal interpolation (linear)

```{r, class.source = 'fold-hide'}
# Existing data
existing_data <- classified_filled_monthly_median[[1]]
current_months <- st_get_dimension_values(classified_filled_monthly_median, "month")

# Create full monthly sequence
full_months <- seq(from = min(current_months), to = max(current_months), by = "month")

# Prepare new array with NAs for missing months
new_dims <- c(dim(classified_filled_monthly_median)[1:2], length(full_months))
new_array <- array(NA, dim = new_dims)

# Map existing data into correct positions
month_idx <- match(current_months, full_months)
new_array[,,month_idx] <- existing_data

# Start from the original dimensions object
dims <- st_dimensions(classified_filled_monthly_median)

# Update the month dimension's values
dims$month$values <- full_months

# Assign new array to the stars object
classified_filled_monthly_median <- st_as_stars(list(data = new_array))

# Attach updated dimensions
st_dimensions(classified_filled_monthly_median) <- dims

plot(classified_filled_monthly_median)
st_dimensions(classified_filled_monthly_median)

# Summarise per month
table_month <-
  classified_filled_monthly_median[,,,] |>
  as_tibble() |>
  group_by(month) |>
  summarize(inundation = mean(data, na.rm = TRUE)*100)


table_month_plotting <- table_month[!is.na(table_month$inundation),] # drop NAs for plotting

ggplot(table_month_plotting) + ## check the dates in table to plot a specific single year
  aes(x = month, y = inundation) +
  ylim(0,100) +
  geom_line() + geom_point() +
  labs(title = "Inundated area %",
       x = "Date",
       y = "Inundated area (%)") +
  theme_minimal()


# extract time points per month
time_vals1m <- st_get_dimension_values(classified_filled_monthly_median, "month")
time_vals <- 1:dim(classified_filled_monthly_median)[3]  # or 1:length(time dimension)

obj_filled_1m <- st_apply(
  classified_filled_monthly_median,
  MARGIN = c("x", "y"),   
  FUN = function(ts) {
    if (all(is.na(ts))) {
      return(ts)
    }
    approx(
      x = seq_along(ts),  # numeric indices of time points
      y = ts,
      xout = seq_along(ts),  # interpolate at same time points
      method = "linear",
      rule = 2
    )$y
  },
  .fname = "month"
)

# fix the broken time dimension in output
obj_filled_1month <- st_set_dimensions(obj_filled_1m, "month", values = time_vals1m)
st_dimensions(classified_filled_monthly_median)
st_dimensions(obj_filled_1month)

ggplot() +
     ggtitle("Per month mean class (Jussila)") +
     geom_stars(data = obj_filled_1month["data"]) +
     geom_sf(data = AOI, fill = NA, color = "red", linewidth = 1) +
     facet_wrap(~month,ncol=12) +
     theme_minimal() +
     theme(axis.text = element_blank(),          # remove axis tick labels
     axis.ticks = element_blank(),         # remove tick marks
     ) +
     scale_fill_gradientn(
         name = "Wetness",
         colors = c("tan", "cyan", "blue"),
         na.value = "gray",
         limits = c(0, 1)
     )

# Plot time series per month (gapfilled)
# first summarise for site area:
table_gf1m <- # Gapfilled table per month
  obj_filled_1m[,,,] |>  
  as_tibble() |>
  group_by(month) |> 
  summarize(inundation = mean(data, na.rm = TRUE)*100)

# New column: Flag gapfilled values
table_gf1m$gapfilled <- "monthly median"
table_gf1m$gapfilled[is.na(table_month$inundation)] <- "gapfilled"
table_gf1m$gapfilled <- as.factor(table_gf1m$gapfilled)
# time format to Date for plotting
table_gf1m$date <- as.Date(table_gf1m$month) 


ggplot(table_gf1m) + #check the dates in table to plot a single year ([65:74,] -> 2018 in this case)
  aes(x = date, y = inundation) + scale_x_date(date_labels = "%b %y") + 
  geom_line() + geom_point(aes(colour = gapfilled), size=2) + 
  scale_color_manual(values = c("gapfilled" = "red", "monthly median" = "black"), name=NULL)+
  labs(title = "Inundation %",x = "Date", 
       y = "Inundated area (%)") +
  ylim(0,100)+
  theme_minimal()

```

Plotting yearly indicators:

```{r, class.source = 'fold-hide'}
# Using per month gapfilled stars object to calculate statistics

# aggregate stars into yearly layers
## Mean (for each pixel?)
obj_y_mean2 <- aggregate(obj_filled_1month, by = "year", 
                        FUN=mean, na.rm=T) 

## Min (for each pixel?)
obj_y_min2 <- aggregate(obj_filled_1month, by = "year", 
                       FUN=min, na.rm=T) # returns Inf for NA areas
obj_y_min2[obj_y_min2 == Inf] <- NA # convert Inf back to NA

## Max (for each pixel?)
obj_y_max2 <- aggregate(obj_filled_1month, by = "year", 
                       FUN=max, na.rm=T) # returns -Inf for NA areas
obj_y_max2[obj_y_max2 == -Inf] <- NA # convert -Inf back to NA


## Plot yearly raster maps
# Inundation (Jussila). Inundated % of time
plot(obj_y_mean2[1], col = viridis(100, option = "D", direction=-1),
     breaks = seq(0, 1, length.out = 101))  

plot(obj_y_min2[1], col = viridis(100, option = "D", direction=-1),
     breaks = seq(0, 1, length.out = 101))  

plot(obj_y_max2[1], col = viridis(100, option = "D", direction=-1),
     breaks = seq(0, 1, length.out = 101))  

# MEAN - summarise values for site area
table_y_mean2 <- 
  obj_y_mean2[,,,] |> 
  as_tibble() |>
  group_by(time) |> 
  summarize(inundation = mean(data, na.rm = TRUE)*100)

#summarise min for sites (site mean at minimum wet situation)
table_y_min2 <- 
  obj_y_min2[,,,] |> 
  as_tibble() |>
  group_by(time) |> 
  summarize(inundation = mean(data, na.rm = TRUE)*100)

#summarise max for sites (site mean at minimum wet situation)
table_y_max2 <- 
  obj_y_max2[,,,] |>  
  as_tibble() |>
  group_by(time) |> 
  summarize(inundation = mean(data, na.rm = TRUE)*100)


# plot percentage of permanently and seasonally wet area. 
# Jussila model
ggplot() +
  ylim(0,100)+ 
  geom_ribbon(aes(x = table_y_mean2$time, # permanent
                  ymin = 0, 
                  ymax = table_y_min2$inundation),fill="#1f9e89", alpha= 0.6)+ 
  geom_ribbon(aes(x = table_y_mean2$time, # seasonal
                  ymin = table_y_min2$inundation, 
                  ymax = table_y_max2$inundation),fill="#6ece58", alpha= 0.3)+  #Temporarily inundated
  geom_ribbon(aes(x = table_y_mean2$time, # never
                  ymin = table_y_max2$inundation, 
                  ymax = 100),fill="#fde725", alpha= 0.2)+ # Never inundated
  labs(title = "Permanently and seasonally inundated area (Jussila model)",
       x = "Year",
       y = "Inundated area %") +
  theme_minimal() + theme(legend.position="none") # + scale_x_date(date_breaks = "1 year")


```
